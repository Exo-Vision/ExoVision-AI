# ëª¨ë¸ ì •í™•ë„: 0.8274


import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

# [1] ë°ì´í„° ë¡œë“œ
data = pd.read_csv("datasets/final_exoplanets.csv")

target = "tfopwg_disp"  # ì‹¤ì œ íƒ€ê²Ÿ ì»¬ëŸ¼ ì´ë¦„
X = data.drop(target, axis=1)
y = data[target]

# -------------------------------
# ë¬¸ìì—´ íƒ€ê²Ÿ -> ìˆ«ì ë³€í™˜
# -------------------------------
le = LabelEncoder()
y = le.fit_transform(y)

# [2] ìŠ¤ì¼€ì¼ë§ & ë¶„í• 
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# [3] ëª¨ë¸ ì •ì˜
rf = RandomForestClassifier(
    n_estimators=600, max_depth=12, min_samples_split=5, min_samples_leaf=2, random_state=42
)
xgb = XGBClassifier(
    n_estimators=600, learning_rate=0.045, max_depth=10,
    subsample=0.98, colsample_bytree=0.85, min_child_weight=1, gamma=0.05,
    tree_method="hist", random_state=42
)
lgb = LGBMClassifier(
    n_estimators=700, learning_rate=0.05, max_depth=9, subsample=0.95,
    colsample_bytree=0.8, min_child_samples=20, reg_lambda=0.7, random_state=42
)
cb = CatBoostClassifier(
    iterations=700,
    learning_rate=0.04,
    depth=9,
    l2_leaf_reg=3,
    bootstrap_type='Bernoulli',   # subsample ì‚¬ìš© ê°€ëŠ¥
    subsample=0.85,
    verbose=False,
    random_state=42
)


# [4] í•™ìŠµ
rf.fit(X_train, y_train)
xgb.fit(X_train, y_train)
lgb.fit(X_train, y_train)
cb.fit(X_train, y_train)

# [5] ê°œë³„ ì˜ˆì¸¡
pred_rf = rf.predict_proba(X_test)
pred_xgb = xgb.predict_proba(X_test)
pred_lgb = lgb.predict_proba(X_test)
pred_cb = cb.predict_proba(X_test)

# [6] Weighted Ensemble (XGB ì¤‘ì‹¬)
weights = np.array([0.2, 0.35, 0.3, 0.15])
final_pred = (
    pred_rf * weights[0]
    + pred_xgb * weights[1]
    + pred_lgb * weights[2]
    + pred_cb * weights[3]
)
final_pred_label = np.argmax(final_pred, axis=1)

# [7] í‰ê°€
acc_rf = accuracy_score(y_test, np.argmax(pred_rf, axis=1))
acc_xgb = accuracy_score(y_test, np.argmax(pred_xgb, axis=1))
acc_lgb = accuracy_score(y_test, np.argmax(pred_lgb, axis=1))
acc_cb = accuracy_score(y_test, np.argmax(pred_cb, axis=1))
acc_final = accuracy_score(y_test, final_pred_label)

print("\n==================== âœ… ìµœì¢… ëª¨ë¸ ì •í™•ë„ ====================")
print(f"RF ì •í™•ë„: {acc_rf:.4f}")
print(f"XGB ì •í™•ë„: {acc_xgb:.4f}")
print(f"LGB ì •í™•ë„: {acc_lgb:.4f}")
print(f"CB ì •í™•ë„: {acc_cb:.4f}")
print(f"\nğŸš€ Weighted Ensemble ìµœì¢… ì •í™•ë„: {acc_final:.4f}")
