"""
3-í´ë˜ìŠ¤ ë¶„ë¥˜ ëª¨ë¸
- CONFIRMED, FALSE POSITIVE, CANDIDATE ëª¨ë‘ ì •ë‹µ ë ˆì´ë¸”ë¡œ ì‚¬ìš©
- ì „ì²´ 21,271ê°œ ë°ì´í„° í™œìš©
- ê°•í•œ ì •ê·œí™” + ì•™ìƒë¸” ë‹¤ì–‘ì„±
- ëª©í‘œ: 3-í´ë˜ìŠ¤ ë¶„ë¥˜ ì •í™•ë„ 95%
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from sklearn.ensemble import StackingClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.linear_model import LogisticRegression

import time

print("="*100)
print("ğŸš€ 3-í´ë˜ìŠ¤ ë¶„ë¥˜ ëª¨ë¸ (CONFIRMED / FALSE POSITIVE / CANDIDATE)")
print("="*100)

# ============================================================================
# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ============================================================================

print("\n" + "="*100)
print("ğŸ“‚ 1. ë°ì´í„° ë¡œë“œ (ì „ì²´ 3-í´ë˜ìŠ¤)")
print("="*100)

df = pd.read_csv('datasets/exoplanets.csv')
print(f"ì „ì²´ ë°ì´í„°: {df.shape[0]} ìƒ˜í”Œ")

# í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
print("\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:")
class_counts = df['koi_disposition'].value_counts()
for label, count in class_counts.items():
    print(f"  â€¢ {label:20s}: {count:5d}ê°œ ({count/len(df)*100:5.1f}%)")

base_features = [
    'koi_prad', 'koi_teq', 'koi_insol', 'koi_period', 'koi_sma', 'koi_impact',
    'koi_eccen', 'koi_depth', 'koi_duration', 'koi_srad', 'koi_smass',
    'koi_steff', 'koi_slogg', 'koi_smet', 'ra', 'dec'
]

# ============================================================================
# íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§
# ============================================================================

print("\nğŸ”§ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§:")

df_fe = df[base_features + ['koi_disposition']].copy()

df_fe['planet_star_ratio'] = df_fe['koi_prad'] / (df_fe['koi_srad'] * 109)
print("  âœ… planet_star_ratio")

df_fe['orbital_energy'] = df_fe['koi_smass'] / df_fe['koi_sma']
print("  âœ… orbital_energy")

df_fe['transit_signal'] = df_fe['koi_depth'] * df_fe['koi_duration']
print("  âœ… transit_signal")

df_fe['habitable_flux'] = np.abs(df_fe['koi_insol'] - 1.0)
print("  âœ… habitable_flux")

df_fe['stellar_density'] = df_fe['koi_smass'] / (df_fe['koi_srad']**3)
print("  âœ… stellar_density")

df_fe['planet_density_proxy'] = df_fe['koi_prad'] / np.sqrt(df_fe['koi_teq'] + 1)
print("  âœ… planet_density_proxy")

df_fe['log_period'] = np.log10(df_fe['koi_period'] + 1)
df_fe['log_depth'] = np.log10(df_fe['koi_depth'] + 1)
df_fe['log_insol'] = np.log10(df_fe['koi_insol'] + 1)
print("  âœ… log ë³€í™˜: period, depth, insol")

df_fe['orbit_stability'] = df_fe['koi_impact'] * (1 - df_fe['koi_eccen'])
print("  âœ… orbit_stability")

# ê²°ì¸¡ì¹˜ ì œê±°
df_clean = df_fe.dropna()

print(f"\nê²°ì¸¡ì¹˜ ì œê±° í›„: {df_clean.shape[0]} ìƒ˜í”Œ ({df_clean.shape[0]/df.shape[0]*100:.1f}%)")

print("\nğŸ“Š ìµœì¢… í´ë˜ìŠ¤ ë¶„í¬:")
final_class_counts = df_clean['koi_disposition'].value_counts()
for label, count in final_class_counts.items():
    print(f"  â€¢ {label:20s}: {count:5d}ê°œ ({count/len(df_clean)*100:5.1f}%)")

# íŠ¹ì§•ê³¼ ë ˆì´ë¸” ë¶„ë¦¬
X = df_clean.drop('koi_disposition', axis=1)
y = df_clean['koi_disposition']

# ë ˆì´ë¸” ì¸ì½”ë”©
le = LabelEncoder()
y_encoded = le.fit_transform(y)

print(f"\nìµœì¢… ë°ì´í„°:")
print(f"  â€¢ íŠ¹ì§•: {X.shape[1]}ê°œ")
print(f"  â€¢ ìƒ˜í”Œ: {X.shape[0]}ê°œ")
print(f"\në ˆì´ë¸” ë§¤í•‘:")
for i, label in enumerate(le.classes_):
    count = np.sum(y_encoded == i)
    print(f"  â€¢ class {i} = {label:20s}: {count:5d}ê°œ")

# Train/Test ë¶„í•  (90/10)
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, 
    test_size=0.1,
    random_state=42,
    stratify=y_encoded
)

print(f"\në°ì´í„° ë¶„í•  (90/10):")
print(f"  â€¢ í•™ìŠµ: {X_train.shape[0]} ìƒ˜í”Œ")
print(f"  â€¢ í…ŒìŠ¤íŠ¸: {X_test.shape[0]} ìƒ˜í”Œ")

# ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")

# ============================================================================
# 2. ê°œë³„ ëª¨ë¸ í•™ìŠµ (3-í´ë˜ìŠ¤ ë¶„ë¥˜)
# ============================================================================

print("\n" + "="*100)
print("ğŸ¯ 2. ê°œë³„ ëª¨ë¸ í•™ìŠµ (3-í´ë˜ìŠ¤ ë¶„ë¥˜)")
print("="*100)

model_results = []

def evaluate_model(name, model, X_train, y_train, X_test, y_test, use_cv=True):
    """ëª¨ë¸ í‰ê°€"""
    
    print(f"\n{'='*100}")
    print(f"ğŸ”¹ {name}")
    print(f"{'='*100}")
    
    start_time = time.time()
    model.fit(X_train, y_train)
    train_time = time.time() - start_time
    
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    
    train_acc = accuracy_score(y_train, y_train_pred)
    test_acc = accuracy_score(y_test, y_test_pred)
    overfitting = train_acc - test_acc
    
    print(f"â±ï¸ í•™ìŠµ ì‹œê°„: {train_time:.2f}ì´ˆ")
    print(f"ğŸ“Š í•™ìŠµ ì •í™•ë„: {train_acc*100:.2f}%")
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc*100:.2f}%")
    print(f"âš ï¸ ê³¼ì í•© ì •ë„: {overfitting*100:.2f}%p", end="")
    
    if overfitting > 0.05:
        print(" (âš ï¸ ê³¼ì í•© ê²½ê³ )")
    elif overfitting > 0.02:
        print(" (âš¡ ì•½ê°„ ê³¼ì í•©)")
    else:
        print(" (âœ… ì–‘í˜¸)")
    
    if use_cv:
        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)
        cv_mean = cv_scores.mean()
        cv_std = cv_scores.std()
        print(f"ğŸ”„ 5-Fold CV: {cv_mean*100:.2f}% Â± {cv_std*100:.2f}%")
    else:
        cv_mean = test_acc
        cv_std = 0.0
        print(f"ğŸ”„ 5-Fold CV: ìƒëµ (ì‹œê°„ ì ˆì•½)")
    
    model_results.append({
        'name': name,
        'model': model,
        'train_acc': train_acc,
        'test_acc': test_acc,
        'cv_mean': cv_mean,
        'cv_std': cv_std,
        'overfitting': overfitting,
        'predictions': y_test_pred
    })
    
    return model

# ============================================================================
# íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ (ê°•í•œ ì •ê·œí™”)
# ============================================================================

print("\n" + "-"*100)
print("ğŸŒ³ íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ (ê°•í•œ ì •ê·œí™”)")
print("-"*100)

# CatBoost
print("\nâ³ CatBoost í•™ìŠµ ì¤‘...")
catboost_model = CatBoostClassifier(
    iterations=500,
    learning_rate=0.03,
    depth=6,
    l2_leaf_reg=10.0,
    bagging_temperature=1.0,
    random_state=42,
    verbose=False
)
evaluate_model("CatBoost", catboost_model, X_train_scaled, y_train, X_test_scaled, y_test)

# XGBoost
print("\nâ³ XGBoost í•™ìŠµ ì¤‘...")
xgboost_model = XGBClassifier(
    n_estimators=500,
    learning_rate=0.03,
    max_depth=6,
    reg_lambda=10.0,
    reg_alpha=2.0,
    subsample=0.6,
    colsample_bytree=0.6,
    random_state=42,
    eval_metric='mlogloss',
    n_jobs=-1
)
evaluate_model("XGBoost", xgboost_model, X_train_scaled, y_train, X_test_scaled, y_test)

# LightGBM
print("\nâ³ LightGBM í•™ìŠµ ì¤‘...")
lightgbm_model = LGBMClassifier(
    n_estimators=500,
    learning_rate=0.03,
    max_depth=6,
    num_leaves=31,
    reg_lambda=10.0,
    reg_alpha=2.0,
    subsample=0.6,
    colsample_bytree=0.6,
    random_state=42,
    verbose=-1,
    n_jobs=-1
)
evaluate_model("LightGBM", lightgbm_model, X_train_scaled, y_train, X_test_scaled, y_test)

# ============================================================================
# ë¹„íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸
# ============================================================================

print("\n" + "-"*100)
print("ğŸ”¬ ë¹„íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸")
print("-"*100)

# SVM (RBF)
print("\nâ³ SVM (RBF) í•™ìŠµ ì¤‘...")
svm_rbf_model = SVC(
    C=1.0,
    kernel='rbf',
    gamma='scale',
    probability=True,
    random_state=42
)
evaluate_model("SVM (RBF)", svm_rbf_model, X_train_scaled, y_train, X_test_scaled, y_test, use_cv=False)

# Neural Network
print("\nâ³ Neural Network í•™ìŠµ ì¤‘...")
mlp_model = MLPClassifier(
    hidden_layer_sizes=(128, 64, 32),
    activation='relu',
    solver='adam',
    alpha=0.01,
    batch_size=128,
    learning_rate_init=0.001,
    max_iter=500,
    early_stopping=True,
    validation_fraction=0.1,
    n_iter_no_change=20,
    random_state=42
)
evaluate_model("Neural Network", mlp_model, X_train_scaled, y_train, X_test_scaled, y_test, use_cv=False)

# ============================================================================
# 3. ì•™ìƒë¸”
# ============================================================================

print("\n" + "="*100)
print("ğŸ¯ 3. ì•™ìƒë¸”")
print("="*100)

# ìƒìœ„ ëª¨ë¸ ì„ íƒ
sorted_results = sorted(model_results, key=lambda x: x['test_acc'], reverse=True)

print("\nğŸ“Š ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„:")
print("-"*100)
print("ìˆœìœ„  ëª¨ë¸                     í…ŒìŠ¤íŠ¸ ì •í™•ë„    CV ì •í™•ë„       ê³¼ì í•©")
print("-"*100)
for i, result in enumerate(sorted_results, 1):
    print(f"{i:2d}.  {result['name']:22s}  {result['test_acc']*100:6.2f}%      "
          f"{result['cv_mean']*100:6.2f}%Â±{result['cv_std']*100:4.2f}%   {result['overfitting']*100:5.2f}%p")

# Top 5 ì„ íƒ
top_n = min(5, len(model_results))
top_models = sorted_results[:top_n]

print(f"\nğŸ† ìƒìœ„ {top_n}ê°œ ëª¨ë¸ ì„ íƒ:")
for i, result in enumerate(top_models, 1):
    print(f"  {i}. {result['name']:22s}  {result['test_acc']*100:.2f}%")

# Soft Voting
print("\n" + "-"*100)
print("ğŸ—³ï¸ Soft Voting Ensemble")
print("-"*100)

voting_estimators = [(result['name'], result['model']) for result in top_models]

voting_clf = VotingClassifier(
    estimators=voting_estimators,
    voting='soft',
    n_jobs=-1
)

print("\nâ³ Soft Voting í•™ìŠµ ì¤‘...")
start_time = time.time()
voting_clf.fit(X_train_scaled, y_train)
train_time = time.time() - start_time

voting_train_acc = accuracy_score(y_train, voting_clf.predict(X_train_scaled))
voting_test_acc = accuracy_score(y_test, voting_clf.predict(X_test_scaled))
voting_overfitting = voting_train_acc - voting_test_acc

print(f"\nâ±ï¸ í•™ìŠµ ì‹œê°„: {train_time:.2f}ì´ˆ")
print(f"ğŸ“Š í•™ìŠµ ì •í™•ë„: {voting_train_acc*100:.2f}%")
print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì •í™•ë„: {voting_test_acc*100:.2f}%")
print(f"âš ï¸ ê³¼ì í•© ì •ë„: {voting_overfitting*100:.2f}%p")

voting_cv = cross_val_score(voting_clf, X_train_scaled, y_train, cv=5, scoring='accuracy', n_jobs=-1)
print(f"ğŸ”„ 5-Fold CV: {voting_cv.mean()*100:.2f}% Â± {voting_cv.std()*100:.2f}%")

# Stacking
print("\n" + "-"*100)
print("ğŸ—ï¸ Stacking Ensemble")
print("-"*100)

base_learners = [(result['name'], result['model']) for result in top_models]

meta_learner = LogisticRegression(
    C=0.5,
    max_iter=1000,
    random_state=42
)

stacking_clf = StackingClassifier(
    estimators=base_learners,
    final_estimator=meta_learner,
    cv=5,
    n_jobs=-1
)

print("\nâ³ Stacking í•™ìŠµ ì¤‘...")
start_time = time.time()
stacking_clf.fit(X_train_scaled, y_train)
train_time = time.time() - start_time

stacking_train_acc = accuracy_score(y_train, stacking_clf.predict(X_train_scaled))
stacking_test_acc = accuracy_score(y_test, stacking_clf.predict(X_test_scaled))
stacking_overfitting = stacking_train_acc - stacking_test_acc

print(f"\nâ±ï¸ í•™ìŠµ ì‹œê°„: {train_time:.2f}ì´ˆ")
print(f"ğŸ“Š í•™ìŠµ ì •í™•ë„: {stacking_train_acc*100:.2f}%")
print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì •í™•ë„: {stacking_test_acc*100:.2f}%")
print(f"âš ï¸ ê³¼ì í•© ì •ë„: {stacking_overfitting*100:.2f}%p")

stacking_cv = cross_val_score(stacking_clf, X_train_scaled, y_train, cv=5, scoring='accuracy', n_jobs=-1)
print(f"ğŸ”„ 5-Fold CV: {stacking_cv.mean()*100:.2f}% Â± {stacking_cv.std()*100:.2f}%")

# ============================================================================
# 4. ìµœì¢… ê²°ê³¼
# ============================================================================

print("\n" + "="*100)
print("ğŸ“Š 4. ìµœì¢… ê²°ê³¼ (3-í´ë˜ìŠ¤ ë¶„ë¥˜)")
print("="*100)

print("\n" + "="*100)
print("ëª¨ë¸                     í•™ìŠµ ì •í™•ë„    í…ŒìŠ¤íŠ¸ ì •í™•ë„    ê³¼ì í•©      CV ì •í™•ë„")
print("="*100)

# ê°œë³„ ëª¨ë¸ (ìƒìœ„ 5ê°œ)
for result in top_models:
    print(f"{result['name']:22s}  {result['train_acc']*100:6.2f}%      {result['test_acc']*100:6.2f}%      "
          f"{result['overfitting']*100:5.2f}%p    {result['cv_mean']*100:6.2f}%Â±{result['cv_std']*100:4.2f}%")

print("-"*100)

# ì•™ìƒë¸”
print(f"{'Soft Voting':22s}  {voting_train_acc*100:6.2f}%      {voting_test_acc*100:6.2f}%      "
      f"{voting_overfitting*100:5.2f}%p    {voting_cv.mean()*100:6.2f}%Â±{voting_cv.std()*100:4.2f}%")

print(f"{'Stacking':22s}  {stacking_train_acc*100:6.2f}%      {stacking_test_acc*100:6.2f}%      "
      f"{stacking_overfitting*100:5.2f}%p    {stacking_cv.mean()*100:6.2f}%Â±{stacking_cv.std()*100:4.2f}%")

print("="*100)

# ìµœê³  ì„±ëŠ¥
all_final_results = [
    ('Soft Voting', voting_test_acc, voting_overfitting),
    ('Stacking', stacking_test_acc, stacking_overfitting)
] + [(r['name'], r['test_acc'], r['overfitting']) for r in top_models]

best_model, best_acc, best_overfit = max(all_final_results, key=lambda x: x[1])

print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model}")
print(f"   â€¢ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {best_acc*100:.2f}%")
print(f"   â€¢ ê³¼ì í•©: {best_overfit*100:.2f}%p")

# ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
print("\n" + "="*100)
print("ğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€")
print("="*100)

target_acc = 0.95
print(f"\nëª©í‘œ: {target_acc*100:.0f}%")
print(f"ë‹¬ì„±: {best_acc*100:.2f}%")
print(f"ì°¨ì´: {(best_acc - target_acc)*100:+.2f}%p")

if best_acc >= target_acc:
    print("\nğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! 95% ëª©í‘œë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!")
elif best_acc >= 0.90:
    print("\nâš¡ 90% ì´ìƒ ë‹¬ì„±! ëª©í‘œì— ê·¼ì ‘í–ˆìŠµë‹ˆë‹¤!")
else:
    print("\nğŸ“Š ì¶”ê°€ ê°œì„  í•„ìš”")

# ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸
print("\n" + "="*100)
print(f"ğŸ“‹ ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸ ({best_model})")
print("="*100)

if best_model == 'Soft Voting':
    y_pred = voting_clf.predict(X_test_scaled)
elif best_model == 'Stacking':
    y_pred = stacking_clf.predict(X_test_scaled)
else:
    best_individual = [r for r in model_results if r['name'] == best_model][0]
    y_pred = best_individual['predictions']

print("\n" + classification_report(y_test, y_pred, target_names=le.classes_))

# í˜¼ë™ í–‰ë ¬
print("\nğŸ“Š í˜¼ë™ í–‰ë ¬:")
cm = confusion_matrix(y_test, y_pred)
print("\nì‹¤ì œ\\ì˜ˆì¸¡      ", end="")
for label in le.classes_:
    print(f"{label[:10]:>12s}", end="")
print()
print("-" * (15 + 12 * len(le.classes_)))

for i, label in enumerate(le.classes_):
    print(f"{label[:12]:12s}  ", end="")
    for j in range(len(le.classes_)):
        print(f"{cm[i,j]:>12d}", end="")
    print()

# í´ë˜ìŠ¤ë³„ ì •í™•ë„
print("\nğŸ“Š í´ë˜ìŠ¤ë³„ ì •í™•ë„:")
for i, label in enumerate(le.classes_):
    class_acc = cm[i,i] / cm[i].sum() if cm[i].sum() > 0 else 0
    print(f"  â€¢ {label:20s}: {class_acc*100:.2f}% ({cm[i,i]}/{cm[i].sum()})")

print("\n" + "="*100)
print("âœ… 3-í´ë˜ìŠ¤ ë¶„ë¥˜ ëª¨ë¸ ì™„ë£Œ!")
print("="*100)
