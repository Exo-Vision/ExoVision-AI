"""
CANDIDATE í¬í•¨ í•™ìŠµ ëª¨ë¸
- CANDIDATE í´ë˜ìŠ¤ë¥¼ í•™ìŠµì— í¬í•¨ (21,271ê°œ ì „ì²´ ë°ì´í„° í™œìš©)
- Semi-supervised learning ë°©ì‹
- ê°•í•œ ì •ê·œí™” + ì•™ìƒë¸” ë‹¤ì–‘ì„±
- ëª©í‘œ: 95% ë‹¬ì„±
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report

from sklearn.ensemble import StackingClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.linear_model import LogisticRegression

import time

print("="*100)
print("ğŸš€ CANDIDATE í¬í•¨ í•™ìŠµ ëª¨ë¸ (95% ëª©í‘œ)")
print("="*100)

# ============================================================================
# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ============================================================================

print("\n" + "="*100)
print("ğŸ“‚ 1. ë°ì´í„° ë¡œë“œ (CANDIDATE í¬í•¨)")
print("="*100)

df = pd.read_csv('datasets/exoplanets.csv')
print(f"ì „ì²´ ë°ì´í„°: {df.shape[0]} ìƒ˜í”Œ")

# í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
print("\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:")
print(df['koi_disposition'].value_counts())

base_features = [
    'koi_prad', 'koi_teq', 'koi_insol', 'koi_period', 'koi_sma', 'koi_impact',
    'koi_eccen', 'koi_depth', 'koi_duration', 'koi_srad', 'koi_smass',
    'koi_steff', 'koi_slogg', 'koi_smet', 'ra', 'dec'
]

# ============================================================================
# íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§
# ============================================================================

print("\nğŸ”§ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§:")

df_fe = df[base_features + ['koi_disposition']].copy()

df_fe['planet_star_ratio'] = df_fe['koi_prad'] / (df_fe['koi_srad'] * 109)
print("  âœ… planet_star_ratio")

df_fe['orbital_energy'] = df_fe['koi_smass'] / df_fe['koi_sma']
print("  âœ… orbital_energy")

df_fe['transit_signal'] = df_fe['koi_depth'] * df_fe['koi_duration']
print("  âœ… transit_signal")

df_fe['habitable_flux'] = np.abs(df_fe['koi_insol'] - 1.0)
print("  âœ… habitable_flux")

df_fe['stellar_density'] = df_fe['koi_smass'] / (df_fe['koi_srad']**3)
print("  âœ… stellar_density")

df_fe['planet_density_proxy'] = df_fe['koi_prad'] / np.sqrt(df_fe['koi_teq'] + 1)
print("  âœ… planet_density_proxy")

df_fe['log_period'] = np.log10(df_fe['koi_period'] + 1)
df_fe['log_depth'] = np.log10(df_fe['koi_depth'] + 1)
df_fe['log_insol'] = np.log10(df_fe['koi_insol'] + 1)
print("  âœ… log ë³€í™˜: period, depth, insol")

df_fe['orbit_stability'] = df_fe['koi_impact'] * (1 - df_fe['koi_eccen'])
print("  âœ… orbit_stability")

df_fe = df_fe.dropna()

print(f"\nê²°ì¸¡ì¹˜ ì œê±° í›„: {df_fe.shape[0]} ìƒ˜í”Œ")
print("\ní´ë˜ìŠ¤ ë¶„í¬ (ê²°ì¸¡ì¹˜ ì œê±° í›„):")
print(df_fe['koi_disposition'].value_counts())

# ============================================================================
# 2. 3-í´ë˜ìŠ¤ í•™ìŠµ ë°ì´í„° ì¤€ë¹„
# ============================================================================

print("\n" + "="*100)
print("ğŸ“Š 2. 3-í´ë˜ìŠ¤ í•™ìŠµ ë°ì´í„° ì¤€ë¹„")
print("="*100)

# ì „ì²´ ë°ì´í„° ì‚¬ìš© (CONFIRMED, FALSE POSITIVE, CANDIDATE)
X_full = df_fe.drop('koi_disposition', axis=1)
y_full = df_fe['koi_disposition']

# ë ˆì´ë¸” ì¸ì½”ë”©
le = LabelEncoder()
y_full_encoded = le.fit_transform(y_full)

print(f"\nì „ì²´ ë°ì´í„°:")
print(f"  â€¢ íŠ¹ì§•: {X_full.shape[1]}ê°œ")
print(f"  â€¢ ìƒ˜í”Œ: {X_full.shape[0]}ê°œ")
print(f"\në ˆì´ë¸” ë¶„í¬:")
for i, label in enumerate(le.classes_):
    count = np.sum(y_full_encoded == i)
    print(f"  â€¢ {label} (class {i}): {count}ê°œ ({count/len(y_full_encoded)*100:.1f}%)")

# Train/Test ë¶„í•  (ì „ì²´ ë°ì´í„°)
X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(
    X_full, y_full_encoded,
    test_size=0.1,
    random_state=42,
    stratify=y_full_encoded
)

# ìŠ¤ì¼€ì¼ë§
scaler_full = StandardScaler()
X_train_full_scaled = scaler_full.fit_transform(X_train_full)
X_test_full_scaled = scaler_full.transform(X_test_full)

print(f"\nì „ì²´ ë°ì´í„° ë¶„í• :")
print(f"  â€¢ í•™ìŠµ: {X_train_full.shape[0]} ìƒ˜í”Œ (CONFIRMED, FALSE POSITIVE, CANDIDATE)")
print(f"  â€¢ í…ŒìŠ¤íŠ¸: {X_test_full.shape[0]} ìƒ˜í”Œ")

# ============================================================================
# 3. 2-í´ë˜ìŠ¤ í‰ê°€ ë°ì´í„° ì¤€ë¹„ (CONFIRMED vs FALSE POSITIVEë§Œ)
# ============================================================================

print("\n" + "="*100)
print("ğŸ“Š 3. 2-í´ë˜ìŠ¤ í‰ê°€ ë°ì´í„° ì¤€ë¹„")
print("="*100)

# í‰ê°€ìš©: CONFIRMED, FALSE POSITIVEë§Œ
df_binary = df_fe[df_fe['koi_disposition'].isin(['CONFIRMED', 'FALSE POSITIVE'])].copy()

X_binary = df_binary.drop('koi_disposition', axis=1)
y_binary = df_binary['koi_disposition']

le_binary = LabelEncoder()
y_binary_encoded = le_binary.fit_transform(y_binary)

# Train/Test ë¶„í•  (2-í´ë˜ìŠ¤)
X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(
    X_binary, y_binary_encoded,
    test_size=0.1,
    random_state=42,
    stratify=y_binary_encoded
)

# ìŠ¤ì¼€ì¼ë§
scaler_binary = StandardScaler()
X_train_binary_scaled = scaler_binary.fit_transform(X_train_binary)
X_test_binary_scaled = scaler_binary.transform(X_test_binary)

print(f"\n2-í´ë˜ìŠ¤ í‰ê°€ ë°ì´í„°:")
print(f"  â€¢ í•™ìŠµ: {X_train_binary.shape[0]} ìƒ˜í”Œ (CONFIRMED, FALSE POSITIVE)")
print(f"  â€¢ í…ŒìŠ¤íŠ¸: {X_test_binary.shape[0]} ìƒ˜í”Œ")

# ============================================================================
# 4. ì „ëµ 1: 3-í´ë˜ìŠ¤ë¡œ í•™ìŠµ í›„ 2-í´ë˜ìŠ¤ ì˜ˆì¸¡
# ============================================================================

print("\n" + "="*100)
print("ğŸ¯ 4. ì „ëµ 1: 3-í´ë˜ìŠ¤ í•™ìŠµ â†’ 2-í´ë˜ìŠ¤ í‰ê°€")
print("="*100)
print("\nğŸ’¡ CANDIDATEë¥¼ í¬í•¨í•œ ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµí•˜ì—¬ ë” ë‚˜ì€ íŒ¨í„´ ì¸ì‹")

model_results_strategy1 = []

def evaluate_3class_model(name, model, X_train_full, y_train_full, X_test_binary, y_test_binary):
    """3-í´ë˜ìŠ¤ë¡œ í•™ìŠµ í›„ 2-í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸"""
    
    print(f"\n{'='*100}")
    print(f"ğŸ”¹ {name} (3-í´ë˜ìŠ¤ í•™ìŠµ)")
    print(f"{'='*100}")
    
    start_time = time.time()
    model.fit(X_train_full, y_train_full)
    train_time = time.time() - start_time
    
    # 3-í´ë˜ìŠ¤ í•™ìŠµ ì •í™•ë„
    train_acc_3class = accuracy_score(y_train_full, model.predict(X_train_full))
    
    # 2-í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
    y_pred_3class = model.predict(X_test_binary)
    
    # CANDIDATE(class 2)ë¥¼ FALSE POSITIVE(class 0)ë¡œ ë§¤í•‘
    y_pred_binary = np.where(y_pred_3class == 2, 0, y_pred_3class)
    
    test_acc = accuracy_score(y_test_binary, y_pred_binary)
    
    print(f"â±ï¸ í•™ìŠµ ì‹œê°„: {train_time:.2f}ì´ˆ")
    print(f"ğŸ“Š 3-í´ë˜ìŠ¤ í•™ìŠµ ì •í™•ë„: {train_acc_3class*100:.2f}%")
    print(f"ğŸ“Š 2-í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc*100:.2f}%")
    
    model_results_strategy1.append({
        'name': name,
        'model': model,
        'test_acc': test_acc
    })
    
    return model, test_acc

# CatBoost (3-í´ë˜ìŠ¤)
print("\nâ³ CatBoost í•™ìŠµ ì¤‘...")
catboost_3class = CatBoostClassifier(
    iterations=500,
    learning_rate=0.03,
    depth=6,
    l2_leaf_reg=10.0,
    bagging_temperature=1.0,
    subsample=0.7,
    random_state=42,
    verbose=False
)
evaluate_3class_model("CatBoost", catboost_3class, X_train_full_scaled, y_train_full, 
                      X_test_binary_scaled, y_test_binary)

# XGBoost (3-í´ë˜ìŠ¤)
print("\nâ³ XGBoost í•™ìŠµ ì¤‘...")
xgboost_3class = XGBClassifier(
    n_estimators=500,
    learning_rate=0.03,
    max_depth=6,
    reg_lambda=10.0,
    reg_alpha=2.0,
    subsample=0.6,
    colsample_bytree=0.6,
    random_state=42,
    eval_metric='mlogloss'
)
evaluate_3class_model("XGBoost", xgboost_3class, X_train_full_scaled, y_train_full,
                      X_test_binary_scaled, y_test_binary)

# LightGBM (3-í´ë˜ìŠ¤)
print("\nâ³ LightGBM í•™ìŠµ ì¤‘...")
lightgbm_3class = LGBMClassifier(
    n_estimators=500,
    learning_rate=0.03,
    max_depth=6,
    num_leaves=31,
    reg_lambda=10.0,
    reg_alpha=2.0,
    subsample=0.6,
    colsample_bytree=0.6,
    random_state=42,
    verbose=-1
)
evaluate_3class_model("LightGBM", lightgbm_3class, X_train_full_scaled, y_train_full,
                      X_test_binary_scaled, y_test_binary)

# Neural Network (3-í´ë˜ìŠ¤)
print("\nâ³ Neural Network í•™ìŠµ ì¤‘...")
mlp_3class = MLPClassifier(
    hidden_layer_sizes=(128, 64, 32),
    activation='relu',
    solver='adam',
    alpha=0.01,
    batch_size=128,
    learning_rate_init=0.001,
    max_iter=500,
    early_stopping=True,
    validation_fraction=0.1,
    n_iter_no_change=20,
    random_state=42
)
evaluate_3class_model("Neural Network", mlp_3class, X_train_full_scaled, y_train_full,
                      X_test_binary_scaled, y_test_binary)

# ============================================================================
# 5. ì „ëµ 2: 2-í´ë˜ìŠ¤ë¡œ ì§ì ‘ í•™ìŠµ (ë¹„êµìš©)
# ============================================================================

print("\n" + "="*100)
print("ğŸ¯ 5. ì „ëµ 2: 2-í´ë˜ìŠ¤ ì§ì ‘ í•™ìŠµ (ë¹„êµìš©)")
print("="*100)

model_results_strategy2 = []

def evaluate_2class_model(name, model, X_train, y_train, X_test, y_test):
    """2-í´ë˜ìŠ¤ ì§ì ‘ í•™ìŠµ"""
    
    print(f"\n{'='*100}")
    print(f"ğŸ”¹ {name} (2-í´ë˜ìŠ¤ í•™ìŠµ)")
    print(f"{'='*100}")
    
    start_time = time.time()
    model.fit(X_train, y_train)
    train_time = time.time() - start_time
    
    test_acc = accuracy_score(y_test, model.predict(X_test))
    
    print(f"â±ï¸ í•™ìŠµ ì‹œê°„: {train_time:.2f}ì´ˆ")
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc*100:.2f}%")
    
    model_results_strategy2.append({
        'name': name,
        'test_acc': test_acc
    })
    
    return test_acc

# CatBoost (2-í´ë˜ìŠ¤)
print("\nâ³ CatBoost í•™ìŠµ ì¤‘...")
catboost_2class = CatBoostClassifier(
    iterations=500,
    learning_rate=0.03,
    depth=6,
    l2_leaf_reg=10.0,
    bagging_temperature=1.0,
    subsample=0.7,
    random_state=42,
    verbose=False
)
evaluate_2class_model("CatBoost", catboost_2class, X_train_binary_scaled, y_train_binary,
                      X_test_binary_scaled, y_test_binary)

# XGBoost (2-í´ë˜ìŠ¤)
print("\nâ³ XGBoost í•™ìŠµ ì¤‘...")
xgboost_2class = XGBClassifier(
    n_estimators=500,
    learning_rate=0.03,
    max_depth=6,
    reg_lambda=10.0,
    reg_alpha=2.0,
    subsample=0.6,
    colsample_bytree=0.6,
    random_state=42,
    eval_metric='logloss'
)
evaluate_2class_model("XGBoost", xgboost_2class, X_train_binary_scaled, y_train_binary,
                      X_test_binary_scaled, y_test_binary)

# LightGBM (2-í´ë˜ìŠ¤)
print("\nâ³ LightGBM í•™ìŠµ ì¤‘...")
lightgbm_2class = LGBMClassifier(
    n_estimators=500,
    learning_rate=0.03,
    max_depth=6,
    num_leaves=31,
    reg_lambda=10.0,
    reg_alpha=2.0,
    subsample=0.6,
    colsample_bytree=0.6,
    random_state=42,
    verbose=-1
)
evaluate_2class_model("LightGBM", lightgbm_2class, X_train_binary_scaled, y_train_binary,
                      X_test_binary_scaled, y_test_binary)

# ============================================================================
# 6. ì•™ìƒë¸” (3-í´ë˜ìŠ¤ ëª¨ë¸ë“¤)
# ============================================================================

print("\n" + "="*100)
print("ğŸ¯ 6. ì•™ìƒë¸” (3-í´ë˜ìŠ¤ í•™ìŠµ ëª¨ë¸ë“¤)")
print("="*100)

# Soft Voting
voting_3class = VotingClassifier(
    estimators=[
        ('catboost', catboost_3class),
        ('xgboost', xgboost_3class),
        ('lightgbm', lightgbm_3class),
        ('mlp', mlp_3class)
    ],
    voting='soft',
    n_jobs=-1
)

print("\nâ³ Voting Ensemble í•™ìŠµ ì¤‘...")
voting_3class.fit(X_train_full_scaled, y_train_full)

y_pred_voting = voting_3class.predict(X_test_binary_scaled)
y_pred_voting_binary = np.where(y_pred_voting == 2, 0, y_pred_voting)
voting_test_acc = accuracy_score(y_test_binary, y_pred_voting_binary)

print(f"ğŸ“Š Voting Ensemble í…ŒìŠ¤íŠ¸ ì •í™•ë„: {voting_test_acc*100:.2f}%")

# Stacking
stacking_3class = StackingClassifier(
    estimators=[
        ('catboost', catboost_3class),
        ('xgboost', xgboost_3class),
        ('lightgbm', lightgbm_3class),
        ('mlp', mlp_3class)
    ],
    final_estimator=LogisticRegression(C=0.5, max_iter=1000, random_state=42),
    cv=5,
    n_jobs=-1
)

print("\nâ³ Stacking Ensemble í•™ìŠµ ì¤‘...")
stacking_3class.fit(X_train_full_scaled, y_train_full)

y_pred_stacking = stacking_3class.predict(X_test_binary_scaled)
y_pred_stacking_binary = np.where(y_pred_stacking == 2, 0, y_pred_stacking)
stacking_test_acc = accuracy_score(y_test_binary, y_pred_stacking_binary)

print(f"ğŸ“Š Stacking Ensemble í…ŒìŠ¤íŠ¸ ì •í™•ë„: {stacking_test_acc*100:.2f}%")

# ============================================================================
# 7. ìµœì¢… ê²°ê³¼ ë¹„êµ
# ============================================================================

print("\n" + "="*100)
print("ğŸ“Š 7. ìµœì¢… ê²°ê³¼ ë¹„êµ")
print("="*100)

print("\n" + "="*100)
print("ì „ëµ 1: 3-í´ë˜ìŠ¤ í•™ìŠµ (CANDIDATE í¬í•¨, 19,128ê°œ ìƒ˜í”Œ)")
print("="*100)
for result in sorted(model_results_strategy1, key=lambda x: x['test_acc'], reverse=True):
    print(f"  â€¢ {result['name']:25s}: {result['test_acc']*100:.2f}%")
print(f"  â€¢ Voting Ensemble        : {voting_test_acc*100:.2f}%")
print(f"  â€¢ Stacking Ensemble      : {stacking_test_acc*100:.2f}%")

print("\n" + "="*100)
print("ì „ëµ 2: 2-í´ë˜ìŠ¤ ì§ì ‘ í•™ìŠµ (CANDIDATE ì œì™¸, 10,085ê°œ ìƒ˜í”Œ)")
print("="*100)
for result in sorted(model_results_strategy2, key=lambda x: x['test_acc'], reverse=True):
    print(f"  â€¢ {result['name']:25s}: {result['test_acc']*100:.2f}%")

# ìµœê³  ì„±ëŠ¥
all_results = [
    ('3-class ' + r['name'], r['test_acc']) for r in model_results_strategy1
] + [
    ('3-class Voting', voting_test_acc),
    ('3-class Stacking', stacking_test_acc),
] + [
    ('2-class ' + r['name'], r['test_acc']) for r in model_results_strategy2
]

best_model, best_acc = max(all_results, key=lambda x: x[1])

print("\n" + "="*100)
print("ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸")
print("="*100)
print(f"\n  â€¢ ëª¨ë¸: {best_model}")
print(f"  â€¢ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {best_acc*100:.2f}%")

# ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
target_acc = 0.95
print("\n" + "="*100)
print("ğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€")
print("="*100)
print(f"\n  â€¢ ëª©í‘œ: {target_acc*100:.0f}%")
print(f"  â€¢ ë‹¬ì„±: {best_acc*100:.2f}%")
print(f"  â€¢ ì°¨ì´: {(best_acc - target_acc)*100:+.2f}%p")

if best_acc >= target_acc:
    print("\nğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! 95% ëª©í‘œë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!")
elif best_acc >= 0.93:
    print("\nâš¡ ëª©í‘œì— ê·¼ì ‘í–ˆìŠµë‹ˆë‹¤! (93%+)")
else:
    print("\nğŸ“Š ì¶”ê°€ ê°œì„  í•„ìš”")

# CANDIDATE í¬í•¨ íš¨ê³¼ ë¶„ì„
best_3class = max(model_results_strategy1, key=lambda x: x['test_acc'])
best_2class = max(model_results_strategy2, key=lambda x: x['test_acc'])
improvement = (best_3class['test_acc'] - best_2class['test_acc']) * 100

print("\n" + "="*100)
print("ğŸ’¡ CANDIDATE í¬í•¨ íš¨ê³¼")
print("="*100)
print(f"\n  â€¢ 2-í´ë˜ìŠ¤ í•™ìŠµ (11,206ê°œ): {best_2class['test_acc']*100:.2f}%")
print(f"  â€¢ 3-í´ë˜ìŠ¤ í•™ìŠµ (21,271ê°œ): {best_3class['test_acc']*100:.2f}%")
print(f"  â€¢ ê°œì„  íš¨ê³¼: {improvement:+.2f}%p")

if improvement > 0.5:
    print("\n  âœ… CANDIDATE í¬í•¨ìœ¼ë¡œ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤!")
elif improvement > 0:
    print("\n  âš¡ CANDIDATE í¬í•¨ìœ¼ë¡œ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤!")
elif improvement > -0.5:
    print("\n  ğŸ“Š ì„±ëŠ¥ ì°¨ì´ê°€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤")
else:
    print("\n  âš ï¸ CANDIDATE í¬í•¨ìœ¼ë¡œ ì„±ëŠ¥ì´ í•˜ë½í–ˆìŠµë‹ˆë‹¤ (ë…¸ì´ì¦ˆ ì¦ê°€)")

# ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸
print("\n" + "="*100)
print(f"ğŸ“‹ ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸ ({best_model})")
print("="*100)

if 'Stacking' in best_model and '3-class' in best_model:
    y_pred_final = y_pred_stacking_binary
elif 'Voting' in best_model and '3-class' in best_model:
    y_pred_final = y_pred_voting_binary
elif '3-class' in best_model:
    model_name = best_model.replace('3-class ', '')
    best_3class_model = [r for r in model_results_strategy1 if r['name'] == model_name][0]['model']
    y_pred_3class_final = best_3class_model.predict(X_test_binary_scaled)
    y_pred_final = np.where(y_pred_3class_final == 2, 0, y_pred_3class_final)
else:
    model_name = best_model.replace('2-class ', '')
    best_2class_model = [r for r in model_results_strategy2 if r['name'] == model_name][0]
    # ì¬í•™ìŠµ í•„ìš”
    print("\n  (2-í´ë˜ìŠ¤ ëª¨ë¸ì˜ ìƒì„¸ ë¦¬í¬íŠ¸ëŠ” ìƒëµ)")
    y_pred_final = None

if y_pred_final is not None:
    print("\n" + classification_report(y_test_binary, y_pred_final, 
                                      target_names=['FALSE POSITIVE', 'CONFIRMED']))

print("\n" + "="*100)
print("âœ… CANDIDATE í¬í•¨ í•™ìŠµ ì™„ë£Œ!")
print("="*100)
