"""
ì²œë¬¸í•™ì  ê³„ì¸µì  ë¶„ë¥˜ (Astronomical Hierarchical Classification)
- 1ë‹¨ê³„: (CONFIRMED + CANDIDATE) vs FALSE POSITIVE - "ì™¸ê³„í–‰ì„± ê°€ëŠ¥ì„±" íŒë‹¨
- 2ë‹¨ê³„: CONFIRMED vs CANDIDATE - "í™•ì • ì—¬ë¶€" íŒë‹¨
- 26ê°œ í”¼ì²˜ ì‚¬ìš© (ê¸°ë³¸ 16ê°œ + ì—”ì§€ë‹ˆì–´ë§ 10ê°œ)
- ê³¼ì í•© ë°©ì§€ ë° 95% ëª©í‘œ ë‹¬ì„±
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score

from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import VotingClassifier, RandomForestClassifier

import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

print("=" * 100)
print("ì²œë¬¸í•™ì  ê³„ì¸µì  ë¶„ë¥˜ ì‹œìŠ¤í…œ")
print("1ë‹¨ê³„: (CONFIRMED + CANDIDATE) vs FALSE POSITIVE")
print("2ë‹¨ê³„: CONFIRMED vs CANDIDATE")
print("=" * 100)

# ============================================================================
# STEP 1: ë°ì´í„° ë¡œë“œ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (26ê°œ í”¼ì²˜)
# ============================================================================
print("\n[STEP 1] ë°ì´í„° ë¡œë“œ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§")
print("-" * 100)

df = pd.read_csv('datasets/exoplanets.csv')
print(f"ì›ë³¸ ë°ì´í„°: {df.shape[0]:,} ìƒ˜í”Œ")

# íƒ€ê²Ÿ ë¶„ë¦¬
y_full = df['koi_disposition']
X_full = df.drop(['koi_disposition', 'kepoi_name'], axis=1, errors='ignore')

# ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
numeric_cols = X_full.select_dtypes(include=[np.number]).columns
X_full = X_full[numeric_cols]
print(f"ê¸°ë³¸ í”¼ì²˜: {len(numeric_cols)}ê°œ")

# ============================================================================
# í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (92% ë‹¬ì„± ëª¨ë¸ì—ì„œ ì‚¬ìš©í•œ 10ê°œ í”¼ì²˜)
# ============================================================================
print("\ní”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì¤‘...")

# 1. í–‰ì„±-í•­ì„± ë¹„ìœ¨ (Planet-Star Radius Ratio)
X_full['planet_star_ratio'] = X_full['koi_prad'] / (X_full['koi_srad'] + 1e-10)

# 2. ê¶¤ë„ ì—ë„ˆì§€ (Orbital Energy)
X_full['orbital_energy'] = 1.0 / (X_full['koi_sma'] + 1e-10)

# 3. í†µê³¼ ì‹ í˜¸ ê°•ë„ (Transit Signal Strength)
X_full['transit_signal'] = X_full['koi_depth'] * X_full['koi_duration']

# 4. í•­ì„± ë°€ë„ (Stellar Density)
X_full['stellar_density'] = X_full['koi_smass'] / (X_full['koi_srad']**3 + 1e-10)

# 5. í–‰ì„± ë°€ë„ í”„ë¡ì‹œ (Planet Density Proxy)
X_full['planet_density_proxy'] = X_full['koi_prad']**3 / (X_full['koi_sma']**2 + 1e-10)

# 6. Log ë³€í™˜ (ì™œë„ ê°ì†Œ)
X_full['log_period'] = np.log1p(X_full['koi_period'])
X_full['log_depth'] = np.log1p(X_full['koi_depth'])
X_full['log_insol'] = np.log1p(X_full['koi_insol'])

# 7. ê¶¤ë„ ì•ˆì •ì„± ì§€í‘œ
X_full['orbit_stability'] = X_full['koi_eccen'] * X_full['koi_impact']

# 8. Transit SNR (Signal-to-Noise Ratio proxy)
X_full['transit_snr'] = X_full['koi_depth'] / (X_full['koi_duration'] + 1e-10)

# NaN ì²˜ë¦¬
X_full = X_full.replace([np.inf, -np.inf], np.nan)
X_full = X_full.fillna(X_full.median())

print(f"ìµœì¢… í”¼ì²˜ ìˆ˜: {X_full.shape[1]}ê°œ")
print(f"ì—”ì§€ë‹ˆì–´ë§ í”¼ì²˜: planet_star_ratio, orbital_energy, transit_signal, stellar_density,")
print(f"                 planet_density_proxy, log_period, log_depth, log_insol,")
print(f"                 orbit_stability, transit_snr")

# ============================================================================
# STEP 2: 1ë‹¨ê³„ ëª¨ë¸ - (CONFIRMED + CANDIDATE) vs FALSE POSITIVE
# ============================================================================
print("\n" + "=" * 100)
print("[STEP 2] 1ë‹¨ê³„ ëª¨ë¸: (CONFIRMED + CANDIDATE) vs FALSE POSITIVE")
print("=" * 100)

# 1ë‹¨ê³„ ë ˆì´ë¸” ìƒì„±: EXOPLANET_LIKE (CONFIRMED + CANDIDATE) vs FALSE_POSITIVE
y_stage1 = y_full.copy()
y_stage1_binary = y_stage1.replace({
    'CONFIRMED': 'EXOPLANET_LIKE',
    'CANDIDATE': 'EXOPLANET_LIKE',
    'FALSE POSITIVE': 'NOT_EXOPLANET',
    'REFUTED': 'NOT_EXOPLANET'
})

# NaN ì œê±°
valid_idx = y_stage1_binary.notna()
X_stage1 = X_full[valid_idx]
y_stage1_binary = y_stage1_binary[valid_idx]

print(f"\n1ë‹¨ê³„ í•™ìŠµ ë°ì´í„°:")
print(f"  ì´ ìƒ˜í”Œ: {len(y_stage1_binary):,}")
for label, count in y_stage1_binary.value_counts().sort_index().items():
    print(f"  {label}: {count:,} ({count/len(y_stage1_binary)*100:.1f}%)")

# ë ˆì´ë¸” ì¸ì½”ë”© (EXOPLANET_LIKE=1, NOT_EXOPLANET=0)
y_stage1_encoded = (y_stage1_binary == 'EXOPLANET_LIKE').astype(int)

# Train/Test ë¶„í• 
X_train_s1, X_test_s1, y_train_s1, y_test_s1 = train_test_split(
    X_stage1, y_stage1_encoded, test_size=0.1, random_state=42, stratify=y_stage1_encoded
)

print(f"\nTrain: {len(y_train_s1):,} / Test: {len(y_test_s1):,}")

# ìŠ¤ì¼€ì¼ë§
scaler_s1 = StandardScaler()
X_train_s1_scaled = scaler_s1.fit_transform(X_train_s1)
X_test_s1_scaled = scaler_s1.transform(X_test_s1)

# ê°•í•œ ì •ê·œí™” ì ìš©
print("\n1ë‹¨ê³„ ëª¨ë¸ í•™ìŠµ ì¤‘ (ê°•í•œ ì •ê·œí™”)...")

models_stage1 = {
    'XGBoost': XGBClassifier(
        n_estimators=500,
        max_depth=4,
        learning_rate=0.02,
        subsample=0.7,
        colsample_bytree=0.7,
        reg_alpha=2.0,
        reg_lambda=10.0,
        random_state=42,
        eval_metric='logloss'
    ),
    'LightGBM': LGBMClassifier(
        n_estimators=500,
        max_depth=4,
        learning_rate=0.02,
        subsample=0.7,
        colsample_bytree=0.7,
        reg_alpha=2.0,
        reg_lambda=10.0,
        random_state=42,
        verbose=-1
    ),
    'CatBoost': CatBoostClassifier(
        iterations=500,
        depth=4,
        learning_rate=0.02,
        l2_leaf_reg=10.0,
        bagging_temperature=1.0,
        random_state=42,
        verbose=False
    ),
    'RandomForest': RandomForestClassifier(
        n_estimators=500,
        max_depth=10,
        min_samples_split=20,
        min_samples_leaf=10,
        max_features='sqrt',
        random_state=42
    )
}

results_stage1 = {}

for name, model in models_stage1.items():
    print(f"\n{name} í•™ìŠµ ì¤‘...")
    
    # í•™ìŠµ
    model.fit(X_train_s1_scaled, y_train_s1)
    
    # ì˜ˆì¸¡
    y_train_pred = model.predict(X_train_s1_scaled)
    y_test_pred = model.predict(X_test_s1_scaled)
    y_test_proba = model.predict_proba(X_test_s1_scaled)
    
    # ì •í™•ë„
    train_acc = accuracy_score(y_train_s1, y_train_pred)
    test_acc = accuracy_score(y_test_s1, y_test_pred)
    
    # Cross-validation
    cv_scores = cross_val_score(model, X_train_s1_scaled, y_train_s1, cv=5, scoring='accuracy')
    
    # AUC
    auc = roc_auc_score(y_test_s1, y_test_proba[:, 1])
    
    results_stage1[name] = {
        'model': model,
        'train_acc': train_acc,
        'test_acc': test_acc,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'overfitting': train_acc - test_acc,
        'auc': auc,
        'y_test_proba': y_test_proba
    }
    
    print(f"  Train ì •í™•ë„: {train_acc:.4f}")
    print(f"  Test ì •í™•ë„:  {test_acc:.4f}")
    print(f"  CV ì •í™•ë„:    {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
    print(f"  ê³¼ì í•©:       {train_acc - test_acc:.4f} ({(train_acc - test_acc)*100:.2f}%p)")
    print(f"  AUC:          {auc:.4f}")

# ì•™ìƒë¸” (Voting)
print("\n1ë‹¨ê³„ ì•™ìƒë¸” (Soft Voting) í•™ìŠµ ì¤‘...")
voting_s1 = VotingClassifier(
    estimators=[(name, model) for name, model in models_stage1.items()],
    voting='soft'
)
voting_s1.fit(X_train_s1_scaled, y_train_s1)

y_train_pred_voting = voting_s1.predict(X_train_s1_scaled)
y_test_pred_voting = voting_s1.predict(X_test_s1_scaled)
y_test_proba_voting = voting_s1.predict_proba(X_test_s1_scaled)

train_acc_voting = accuracy_score(y_train_s1, y_train_pred_voting)
test_acc_voting = accuracy_score(y_test_s1, y_test_pred_voting)
cv_scores_voting = cross_val_score(voting_s1, X_train_s1_scaled, y_train_s1, cv=5, scoring='accuracy')
auc_voting = roc_auc_score(y_test_s1, y_test_proba_voting[:, 1])

print(f"  Train ì •í™•ë„: {train_acc_voting:.4f}")
print(f"  Test ì •í™•ë„:  {test_acc_voting:.4f}")
print(f"  CV ì •í™•ë„:    {cv_scores_voting.mean():.4f} Â± {cv_scores_voting.std():.4f}")
print(f"  ê³¼ì í•©:       {train_acc_voting - test_acc_voting:.4f} ({(train_acc_voting - test_acc_voting)*100:.2f}%p)")
print(f"  AUC:          {auc_voting:.4f}")

results_stage1['Voting'] = {
    'model': voting_s1,
    'train_acc': train_acc_voting,
    'test_acc': test_acc_voting,
    'cv_mean': cv_scores_voting.mean(),
    'cv_std': cv_scores_voting.std(),
    'overfitting': train_acc_voting - test_acc_voting,
    'auc': auc_voting,
    'y_test_proba': y_test_proba_voting
}

# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
best_model_s1 = max(results_stage1.items(), key=lambda x: x[1]['test_acc'])
print(f"\nâœ… 1ë‹¨ê³„ ìµœê³  ëª¨ë¸: {best_model_s1[0]} - Test ì •í™•ë„: {best_model_s1[1]['test_acc']:.4f}")

# ============================================================================
# STEP 3: 2ë‹¨ê³„ ëª¨ë¸ - CONFIRMED vs CANDIDATE
# ============================================================================
print("\n" + "=" * 100)
print("[STEP 3] 2ë‹¨ê³„ ëª¨ë¸: CONFIRMED vs CANDIDATE")
print("=" * 100)

# 2ë‹¨ê³„: CONFIRMED vs CANDIDATEë§Œ ì‚¬ìš©
y_stage2 = y_full[y_full.isin(['CONFIRMED', 'CANDIDATE'])]
X_stage2 = X_full.loc[y_stage2.index]

print(f"\n2ë‹¨ê³„ í•™ìŠµ ë°ì´í„°:")
print(f"  ì´ ìƒ˜í”Œ: {len(y_stage2):,}")
for label, count in y_stage2.value_counts().sort_index().items():
    print(f"  {label}: {count:,} ({count/len(y_stage2)*100:.1f}%)")

# ë ˆì´ë¸” ì¸ì½”ë”© (CONFIRMED=1, CANDIDATE=0)
y_stage2_encoded = (y_stage2 == 'CONFIRMED').astype(int)

# Train/Test ë¶„í• 
X_train_s2, X_test_s2, y_train_s2, y_test_s2 = train_test_split(
    X_stage2, y_stage2_encoded, test_size=0.1, random_state=42, stratify=y_stage2_encoded
)

print(f"\nTrain: {len(y_train_s2):,} / Test: {len(y_test_s2):,}")

# ìŠ¤ì¼€ì¼ë§
scaler_s2 = StandardScaler()
X_train_s2_scaled = scaler_s2.fit_transform(X_train_s2)
X_test_s2_scaled = scaler_s2.transform(X_test_s2)

# ê°•í•œ ì •ê·œí™” ì ìš©
print("\n2ë‹¨ê³„ ëª¨ë¸ í•™ìŠµ ì¤‘ (ê°•í•œ ì •ê·œí™”)...")

models_stage2 = {
    'XGBoost': XGBClassifier(
        n_estimators=500,
        max_depth=4,
        learning_rate=0.02,
        subsample=0.7,
        colsample_bytree=0.7,
        reg_alpha=2.0,
        reg_lambda=10.0,
        random_state=42,
        eval_metric='logloss'
    ),
    'LightGBM': LGBMClassifier(
        n_estimators=500,
        max_depth=4,
        learning_rate=0.02,
        subsample=0.7,
        colsample_bytree=0.7,
        reg_alpha=2.0,
        reg_lambda=10.0,
        random_state=42,
        verbose=-1
    ),
    'CatBoost': CatBoostClassifier(
        iterations=500,
        depth=4,
        learning_rate=0.02,
        l2_leaf_reg=10.0,
        bagging_temperature=1.0,
        random_state=42,
        verbose=False
    ),
    'RandomForest': RandomForestClassifier(
        n_estimators=500,
        max_depth=10,
        min_samples_split=20,
        min_samples_leaf=10,
        max_features='sqrt',
        random_state=42
    )
}

results_stage2 = {}

for name, model in models_stage2.items():
    print(f"\n{name} í•™ìŠµ ì¤‘...")
    
    # í•™ìŠµ
    model.fit(X_train_s2_scaled, y_train_s2)
    
    # ì˜ˆì¸¡
    y_train_pred = model.predict(X_train_s2_scaled)
    y_test_pred = model.predict(X_test_s2_scaled)
    y_test_proba = model.predict_proba(X_test_s2_scaled)
    
    # ì •í™•ë„
    train_acc = accuracy_score(y_train_s2, y_train_pred)
    test_acc = accuracy_score(y_test_s2, y_test_pred)
    
    # Cross-validation
    cv_scores = cross_val_score(model, X_train_s2_scaled, y_train_s2, cv=5, scoring='accuracy')
    
    # AUC
    auc = roc_auc_score(y_test_s2, y_test_proba[:, 1])
    
    results_stage2[name] = {
        'model': model,
        'train_acc': train_acc,
        'test_acc': test_acc,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'overfitting': train_acc - test_acc,
        'auc': auc,
        'y_test_proba': y_test_proba
    }
    
    print(f"  Train ì •í™•ë„: {train_acc:.4f}")
    print(f"  Test ì •í™•ë„:  {test_acc:.4f}")
    print(f"  CV ì •í™•ë„:    {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
    print(f"  ê³¼ì í•©:       {train_acc - test_acc:.4f} ({(train_acc - test_acc)*100:.2f}%p)")
    print(f"  AUC:          {auc:.4f}")

# ì•™ìƒë¸”
print("\n2ë‹¨ê³„ ì•™ìƒë¸” (Soft Voting) í•™ìŠµ ì¤‘...")
voting_s2 = VotingClassifier(
    estimators=[(name, model) for name, model in models_stage2.items()],
    voting='soft'
)
voting_s2.fit(X_train_s2_scaled, y_train_s2)

y_train_pred_voting = voting_s2.predict(X_train_s2_scaled)
y_test_pred_voting = voting_s2.predict(X_test_s2_scaled)
y_test_proba_voting = voting_s2.predict_proba(X_test_s2_scaled)

train_acc_voting = accuracy_score(y_train_s2, y_train_pred_voting)
test_acc_voting = accuracy_score(y_test_s2, y_test_pred_voting)
cv_scores_voting = cross_val_score(voting_s2, X_train_s2_scaled, y_train_s2, cv=5, scoring='accuracy')
auc_voting = roc_auc_score(y_test_s2, y_test_proba_voting[:, 1])

print(f"  Train ì •í™•ë„: {train_acc_voting:.4f}")
print(f"  Test ì •í™•ë„:  {test_acc_voting:.4f}")
print(f"  CV ì •í™•ë„:    {cv_scores_voting.mean():.4f} Â± {cv_scores_voting.std():.4f}")
print(f"  ê³¼ì í•©:       {train_acc_voting - test_acc_voting:.4f} ({(train_acc_voting - test_acc_voting)*100:.2f}%p)")
print(f"  AUC:          {auc_voting:.4f}")

results_stage2['Voting'] = {
    'model': voting_s2,
    'train_acc': train_acc_voting,
    'test_acc': test_acc_voting,
    'cv_mean': cv_scores_voting.mean(),
    'cv_std': cv_scores_voting.std(),
    'overfitting': train_acc_voting - test_acc_voting,
    'auc': auc_voting,
    'y_test_proba': y_test_proba_voting
}

# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
best_model_s2 = max(results_stage2.items(), key=lambda x: x[1]['test_acc'])
print(f"\nâœ… 2ë‹¨ê³„ ìµœê³  ëª¨ë¸: {best_model_s2[0]} - Test ì •í™•ë„: {best_model_s2[1]['test_acc']:.4f}")

# ============================================================================
# STEP 4: íŒŒì´í”„ë¼ì¸ í†µí•© ë° í™•ì‹ ë„ ì„ê³„ê°’ ìµœì í™”
# ============================================================================
print("\n" + "=" * 100)
print("[STEP 4] íŒŒì´í”„ë¼ì¸ í†µí•© ë° í™•ì‹ ë„ ì„ê³„ê°’ ìµœì í™”")
print("=" * 100)

# ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
y_test_full = y_full.loc[X_test_s1.index]
X_test_full_scaled = scaler_s1.transform(X_test_s1)

# 1ë‹¨ê³„ ëª¨ë¸ë¡œ ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
best_stage1_model = results_stage1['Voting']['model']
stage1_proba = best_stage1_model.predict_proba(X_test_full_scaled)
stage1_pred = best_stage1_model.predict(X_test_full_scaled)

# ê° í™•ì‹ ë„ ì„ê³„ê°’ë³„ ì„±ëŠ¥ í‰ê°€
thresholds = np.arange(0.85, 0.96, 0.01)
threshold_results = []

print("\ní™•ì‹ ë„ ì„ê³„ê°’ ìµœì í™” ì¤‘...")
print(f"{'ì„ê³„ê°’':<10} {'1ë‹¨ê³„ ì‚¬ìš©':<12} {'2ë‹¨ê³„ ì‚¬ìš©':<12} {'ìµœì¢… ì •í™•ë„':<12} {'ìƒì„¸'}")
print("-" * 100)

for threshold in thresholds:
    # ìµœì¢… ì˜ˆì¸¡ ì´ˆê¸°í™”
    final_predictions = np.empty(len(y_test_full), dtype=object)
    
    # 1ë‹¨ê³„ ì˜ˆì¸¡: EXOPLANET_LIKE (1) vs NOT_EXOPLANET (0)
    # í™•ì‹ ë„ê°€ ë†’ì€ ìƒ˜í”Œë§Œ 1ë‹¨ê³„ ê²°ê³¼ ì‚¬ìš©
    high_confidence_mask = (stage1_proba.max(axis=1) >= threshold)
    
    # 1ë‹¨ê³„ ê³ í™•ì‹ ë„ ì¼€ì´ìŠ¤ ì²˜ë¦¬
    for idx in range(len(y_test_full)):
        if high_confidence_mask[idx]:
            if stage1_pred[idx] == 0:  # NOT_EXOPLANET
                final_predictions[idx] = 'FALSE POSITIVE'
            # stage1_pred[idx] == 1 (EXOPLANET_LIKE)ì¸ ê²½ìš°ëŠ” ì•„ë˜ 2ë‹¨ê³„ì—ì„œ ì²˜ë¦¬
    
    # 2ë‹¨ê³„: EXOPLANET_LIKEë¡œ ì˜ˆì¸¡ë˜ì—ˆê±°ë‚˜ í™•ì‹ ë„ê°€ ë‚®ì€ ì¼€ì´ìŠ¤
    # â†’ CONFIRMED vs CANDIDATE êµ¬ë¶„
    needs_stage2_mask = (stage1_pred == 1) | (~high_confidence_mask)
    
    # 2ë‹¨ê³„ ëª¨ë¸ë¡œ ì˜ˆì¸¡
    X_for_stage2 = X_test_full_scaled[needs_stage2_mask]
    
    if len(X_for_stage2) > 0:
        # 2ë‹¨ê³„ ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ë³€í™˜
        X_for_stage2_rescaled = scaler_s2.transform(
            pd.DataFrame(X_for_stage2, columns=X_stage2.columns).fillna(X_stage2.median())
        )
        stage2_pred = results_stage2['Voting']['model'].predict(X_for_stage2_rescaled)
        
        # CONFIRMED=1, CANDIDATE=0
        final_predictions[needs_stage2_mask] = np.where(
            stage2_pred == 1,
            'CONFIRMED',
            'CANDIDATE'
        )
    
    # ì •í™•ë„ ê³„ì‚°
    accuracy = accuracy_score(y_test_full, final_predictions)
    
    # 1ë‹¨ê³„/2ë‹¨ê³„ ì‚¬ìš© ë¹„ìœ¨
    stage1_ratio = high_confidence_mask.sum() / len(y_test_full) * 100
    stage2_ratio = needs_stage2_mask.sum() / len(y_test_full) * 100
    
    threshold_results.append({
        'threshold': threshold,
        'accuracy': accuracy,
        'stage1_ratio': stage1_ratio,
        'stage2_ratio': stage2_ratio,
        'stage1_count': high_confidence_mask.sum(),
        'stage2_count': needs_stage2_mask.sum()
    })
    
    print(f"{threshold:.2f}      {stage1_ratio:>5.1f}%      {stage2_ratio:>5.1f}%      "
          f"{accuracy:.4f}      (1ë‹¨ê³„:{high_confidence_mask.sum()}, 2ë‹¨ê³„:{needs_stage2_mask.sum()})")

# ìµœì  ì„ê³„ê°’ ì„ íƒ
best_threshold_result = max(threshold_results, key=lambda x: x['accuracy'])
best_threshold = best_threshold_result['threshold']
best_accuracy = best_threshold_result['accuracy']

print("\n" + "=" * 100)
print(f"âœ… ìµœì  í™•ì‹ ë„ ì„ê³„ê°’: {best_threshold:.2f}")
print(f"âœ… ìµœì¢… ì •í™•ë„: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)")
print(f"   1ë‹¨ê³„ ì‚¬ìš©: {best_threshold_result['stage1_ratio']:.1f}% ({best_threshold_result['stage1_count']}ê°œ)")
print(f"   2ë‹¨ê³„ ì‚¬ìš©: {best_threshold_result['stage2_ratio']:.1f}% ({best_threshold_result['stage2_count']}ê°œ)")
print("=" * 100)

# ìµœì  ì„ê³„ê°’ìœ¼ë¡œ ìµœì¢… ì˜ˆì¸¡
final_predictions = np.empty(len(y_test_full), dtype=object)
high_confidence_mask = (stage1_proba.max(axis=1) >= best_threshold)

# 1ë‹¨ê³„ ê³ í™•ì‹ ë„ ì¼€ì´ìŠ¤: NOT_EXOPLANET â†’ FALSE POSITIVE
for idx in range(len(y_test_full)):
    if high_confidence_mask[idx] and stage1_pred[idx] == 0:
        final_predictions[idx] = 'FALSE POSITIVE'

# 2ë‹¨ê³„: EXOPLANET_LIKEë¡œ ì˜ˆì¸¡ë˜ì—ˆê±°ë‚˜ í™•ì‹ ë„ê°€ ë‚®ì€ ì¼€ì´ìŠ¤
needs_stage2_mask = (stage1_pred == 1) | (~high_confidence_mask)
X_for_stage2 = X_test_full_scaled[needs_stage2_mask]

if len(X_for_stage2) > 0:
    X_for_stage2_rescaled = scaler_s2.transform(
        pd.DataFrame(X_for_stage2, columns=X_stage2.columns).fillna(X_stage2.median())
    )
    stage2_pred = results_stage2['Voting']['model'].predict(X_for_stage2_rescaled)
    final_predictions[needs_stage2_mask] = np.where(
        stage2_pred == 1,
        'CONFIRMED',
        'CANDIDATE'
    )

# ============================================================================
# STEP 5: ê³¼ì í•© ë¶„ì„
# ============================================================================
print("\n" + "=" * 100)
print("[STEP 5] ê³¼ì í•© ë¶„ì„")
print("=" * 100)

print("\n1ë‹¨ê³„ ëª¨ë¸ (EXOPLANET_LIKE vs NOT_EXOPLANET) ê³¼ì í•© ë¶„ì„:")
print("-" * 100)
for name, result in results_stage1.items():
    status = "âœ…" if result['overfitting'] < 0.03 else "âš ï¸"
    print(f"{status} {name:20} Train: {result['train_acc']:.4f}  Test: {result['test_acc']:.4f}  "
          f"ê³¼ì í•©: {result['overfitting']:.4f} ({result['overfitting']*100:.2f}%p)")

print("\n2ë‹¨ê³„ ëª¨ë¸ (CONFIRMED vs CANDIDATE) ê³¼ì í•© ë¶„ì„:")
print("-" * 100)
for name, result in results_stage2.items():
    status = "âœ…" if result['overfitting'] < 0.03 else "âš ï¸"
    print(f"{status} {name:20} Train: {result['train_acc']:.4f}  Test: {result['test_acc']:.4f}  "
          f"ê³¼ì í•©: {result['overfitting']:.4f} ({result['overfitting']*100:.2f}%p)")

# ê³¼ì í•© íŒì •
overfitting_threshold = 0.03
stage1_overfitting = [(name, r['overfitting']) for name, r in results_stage1.items() 
                      if r['overfitting'] > overfitting_threshold]
stage2_overfitting = [(name, r['overfitting']) for name, r in results_stage2.items() 
                      if r['overfitting'] > overfitting_threshold]

if not stage1_overfitting and not stage2_overfitting:
    print("\nâœ…âœ… ëª¨ë“  ëª¨ë¸ ê³¼ì í•© ì—†ìŒ! (3%p ê¸°ì¤€)")
else:
    if stage1_overfitting:
        print(f"\nâš ï¸ 1ë‹¨ê³„ ê³¼ì í•© ëª¨ë¸: {', '.join([f'{n}({o*100:.2f}%p)' for n, o in stage1_overfitting])}")
    if stage2_overfitting:
        print(f"âš ï¸ 2ë‹¨ê³„ ê³¼ì í•© ëª¨ë¸: {', '.join([f'{n}({o*100:.2f}%p)' for n, o in stage2_overfitting])}")

# ============================================================================
# STEP 6: ìµœì¢… ì„±ëŠ¥ í‰ê°€
# ============================================================================
print("\n" + "=" * 100)
print("[STEP 6] ìµœì¢… ì„±ëŠ¥ í‰ê°€")
print("=" * 100)

# Confusion Matrix
cm = confusion_matrix(y_test_full, final_predictions, 
                      labels=['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE'])

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE'],
            yticklabels=['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE'])
plt.title(f'Confusion Matrix (ì²œë¬¸í•™ì  ê³„ì¸µ ë¶„ë¥˜) - ì •í™•ë„: {best_accuracy:.4f}')
plt.ylabel('ì‹¤ì œ')
plt.xlabel('ì˜ˆì¸¡')
plt.tight_layout()
plt.savefig('confusion_matrix_astronomical.png', dpi=150, bbox_inches='tight')
print("\nâœ… Confusion Matrix ì €ì¥: confusion_matrix_astronomical.png")

# Classification Report
print("\nClassification Report:")
print(classification_report(y_test_full, final_predictions, 
                           labels=['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE'],
                           target_names=['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE']))

# í´ë˜ìŠ¤ë³„ ì •í™•ë„
print("\ní´ë˜ìŠ¤ë³„ ì •í™•ë„:")
for label in ['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE']:
    mask = y_test_full == label
    if mask.sum() > 0:
        class_acc = accuracy_score(y_test_full[mask], final_predictions[mask])
        print(f"  {label:20} {class_acc:.4f} ({class_acc*100:.2f}%)  (ìƒ˜í”Œ: {mask.sum()}ê°œ)")

# ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
target_accuracy = 0.95
gap = best_accuracy - target_accuracy

print("\n" + "=" * 100)
print("ğŸ¯ ëª©í‘œ ë‹¬ì„± í‰ê°€")
print("=" * 100)
print(f"ëª©í‘œ ì •í™•ë„: {target_accuracy:.4f} (95%)")
print(f"ë‹¬ì„± ì •í™•ë„: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)")
print(f"ê²©ì°¨:        {gap:.4f} ({gap*100:.2f}%p)")

if best_accuracy >= target_accuracy:
    print("\nğŸ‰ğŸ‰ğŸ‰ ëª©í‘œ ë‹¬ì„±! 95% ì´ìƒ ì •í™•ë„ ë‹¬ì„±! ğŸ‰ğŸ‰ğŸ‰")
else:
    print(f"\nğŸ“Š ëª©í‘œ ë¯¸ë‹¬ì„±. ì¶”ê°€ ê°œì„  í•„ìš”: {abs(gap)*100:.2f}%p í–¥ìƒ í•„ìš”")
    print("\nğŸ’¡ ì¶”ê°€ ê°œì„  ë°©ì•ˆ:")
    print("  1. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Optuna ìµœì í™”)")
    print("  2. ë°ì´í„° ì¦ê°• (SMOTE, ADASYN)")
    print("  3. ì•™ìƒë¸” Stacking (ë©”íƒ€ ëª¨ë¸)")
    print("  4. ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ê°€ (Neural Network)")
    print("  5. í”¼ì²˜ ì„ íƒ ìµœì í™” (Recursive Feature Elimination)")

print("\n" + "=" * 100)
print("âœ… ë¶„ì„ ì™„ë£Œ")
print("=" * 100)
