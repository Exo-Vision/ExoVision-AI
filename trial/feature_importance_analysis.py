"""
Feature Importance ë¶„ì„ - í•µì‹¬ 5ê°œ ì»¬ëŸ¼ ì¶”ì¶œ
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
import warnings
warnings.filterwarnings('ignore')

print("=" * 100)
print("ğŸ” Feature Importance ë¶„ì„ - í•µì‹¬ ì»¬ëŸ¼ ì¶”ì¶œ")
print("=" * 100)

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv('datasets/exoplanets.csv', low_memory=False)
print(f"\nì›ë³¸ ë°ì´í„°: {df.shape[0]:,} ìƒ˜í”Œ")

y_full = df['koi_disposition']
X_full = df.drop(['koi_disposition', 'kepoi_name'], axis=1, errors='ignore')

# ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ
numeric_cols = X_full.select_dtypes(include=[np.number]).columns
X_full = X_full[numeric_cols]

# í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
X_full['planet_star_ratio'] = X_full['koi_prad'] / (X_full['koi_srad'] + 1e-10)
X_full['orbital_energy'] = 1.0 / (X_full['koi_sma'] + 1e-10)
X_full['transit_signal'] = X_full['koi_depth'] * X_full['koi_duration']
X_full['stellar_density'] = X_full['koi_smass'] / (X_full['koi_srad']**3 + 1e-10)
X_full['planet_density_proxy'] = X_full['koi_prad']**3 / (X_full['koi_sma']**2 + 1e-10)
X_full['log_period'] = np.log1p(X_full['koi_period'])
X_full['log_depth'] = np.log1p(X_full['koi_depth'])
X_full['log_insol'] = np.log1p(X_full['koi_insol'])
X_full['orbit_stability'] = X_full['koi_eccen'] * X_full['koi_impact']
X_full['transit_snr'] = X_full['koi_depth'] / (X_full['koi_duration'] + 1e-10)

X_full = X_full.replace([np.inf, -np.inf], np.nan)
X_full = X_full.fillna(X_full.median())

# ëª¨ë¸ 1: CONFIRMED vs FALSE POSITIVEë¡œ importance ë¶„ì„
y_binary = y_full[y_full.isin(['CONFIRMED', 'FALSE POSITIVE'])]
X_binary = X_full.loc[y_binary.index]
y_binary_encoded = (y_binary == 'CONFIRMED').astype(int)

X_train, X_test, y_train, y_test = train_test_split(
    X_binary, y_binary_encoded, test_size=0.2, random_state=42, stratify=y_binary_encoded
)

print(f"\ní•™ìŠµ ë°ì´í„°: {len(X_train):,} ìƒ˜í”Œ")

# Feature Importance ê³„ì‚°
feature_names = X_train.columns.tolist()
importance_dict = {}

print("\n" + "=" * 100)
print("ğŸ“Š ëª¨ë¸ë³„ Feature Importance ê³„ì‚°")
print("=" * 100)

# CatBoost
print("\n[1/3] CatBoost í•™ìŠµ ì¤‘...")
cat = CatBoostClassifier(
    iterations=500,
    learning_rate=0.02,
    depth=4,
    l2_leaf_reg=10.0,
    random_state=42,
    verbose=False
)
cat.fit(X_train, y_train)
importance_dict['CatBoost'] = cat.feature_importances_

# XGBoost
print("[2/3] XGBoost í•™ìŠµ ì¤‘...")
xgb = XGBClassifier(
    n_estimators=500,
    learning_rate=0.02,
    max_depth=4,
    reg_lambda=10.0,
    subsample=0.7,
    colsample_bytree=0.7,
    random_state=42,
    eval_metric='logloss'
)
xgb.fit(X_train, y_train)
importance_dict['XGBoost'] = xgb.feature_importances_

# LightGBM
print("[3/3] LightGBM í•™ìŠµ ì¤‘...")
lgb = LGBMClassifier(
    n_estimators=500,
    learning_rate=0.02,
    max_depth=4,
    reg_lambda=10.0,
    subsample=0.7,
    colsample_bytree=0.7,
    random_state=42,
    verbose=-1
)
lgb.fit(X_train, y_train)
importance_dict['LightGBM'] = lgb.feature_importances_

# í‰ê·  importance ê³„ì‚°
print("\n" + "=" * 100)
print("ğŸ¯ í†µí•© Feature Importance (3ê°œ ëª¨ë¸ í‰ê· )")
print("=" * 100)

# ì •ê·œí™”ëœ importance í‰ê· 
normalized_importance = {}
for model_name, importances in importance_dict.items():
    # ì •ê·œí™” (í•©ì´ 1ì´ ë˜ë„ë¡)
    normalized = importances / importances.sum()
    normalized_importance[model_name] = normalized

# í‰ê·  ê³„ì‚°
avg_importance = np.mean([normalized_importance[m] for m in normalized_importance.keys()], axis=0)

# DataFrameìœ¼ë¡œ ì •ë¦¬
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': avg_importance,
    'CatBoost': normalized_importance['CatBoost'],
    'XGBoost': normalized_importance['XGBoost'],
    'LightGBM': normalized_importance['LightGBM']
})

importance_df = importance_df.sort_values('Importance', ascending=False)

print("\nìƒìœ„ 10ê°œ í”¼ì²˜:")
print("-" * 100)
print(f"{'ìˆœìœ„':<5} {'í”¼ì²˜ëª…':<30} {'í‰ê·  ì¤‘ìš”ë„':<12} {'CatBoost':<12} {'XGBoost':<12} {'LightGBM':<12}")
print("-" * 100)
for idx, row in importance_df.head(10).iterrows():
    print(f"{importance_df.index.get_loc(idx)+1:<5} {row['Feature']:<30} "
          f"{row['Importance']:.6f}    {row['CatBoost']:.6f}    "
          f"{row['XGBoost']:.6f}    {row['LightGBM']:.6f}")

# í•µì‹¬ 5ê°œ ì»¬ëŸ¼
top5_features = importance_df.head(5)['Feature'].tolist()

print("\n" + "=" * 100)
print("â­ í•µì‹¬ 5ê°œ ì»¬ëŸ¼")
print("=" * 100)
for i, feat in enumerate(top5_features, 1):
    imp = importance_df[importance_df['Feature'] == feat]['Importance'].values[0]
    print(f"{i}. {feat:<30} (ì¤‘ìš”ë„: {imp:.4f})")

# ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ë“¤ì˜ ê¸°ë³¸ê°’ ê³„ì‚°
print("\n" + "=" * 100)
print("ğŸ“‹ ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ë“¤ì˜ ê¸°ë³¸ê°’ (ì¤‘ì•™ê°’/í‰ê· )")
print("=" * 100)

other_features = [f for f in feature_names if f not in top5_features]

# í†µê³„ ì •ë³´ ì¶œë ¥
print(f"\n{'ì»¬ëŸ¼ëª…':<30} {'ì¤‘ì•™ê°’':<15} {'í‰ê· ê°’':<15} {'í‘œì¤€í¸ì°¨':<15} {'ì¶”ì²œê°’':<15}")
print("-" * 100)

default_values = {}
for feat in other_features:
    median_val = X_full[feat].median()
    mean_val = X_full[feat].mean()
    std_val = X_full[feat].std()
    
    # ì¶”ì²œê°’: ì¤‘ì•™ê°’ ì„ íƒ (ë” ì•ˆì •ì )
    recommended = median_val
    default_values[feat] = recommended
    
    print(f"{feat:<30} {median_val:<15.6f} {mean_val:<15.6f} {std_val:<15.6f} {recommended:<15.6f}")

# ê²°ê³¼ ì €ì¥
print("\n" + "=" * 100)
print("ğŸ’¾ ê²°ê³¼ ì €ì¥")
print("=" * 100)

# 1. Feature Importance CSV
importance_df.to_csv('feature_importance_ranking.csv', index=False)
print("âœ… Feature Importance: feature_importance_ranking.csv")

# 2. ê¸°ë³¸ê°’ ì„¤ì • íŒŒì¼
config_data = {
    'top5_features': top5_features,
    'default_values': default_values
}

import json
with open('model_config_top5.json', 'w', encoding='utf-8') as f:
    json.dump(config_data, f, indent=2, ensure_ascii=False)
print("âœ… ì„¤ì • íŒŒì¼: model_config_top5.json")

# 3. ì‚¬ìš© ì˜ˆì œ ì½”ë“œ ìƒì„±
example_code = f"""# ========================================
# í•µì‹¬ 5ê°œ ì»¬ëŸ¼ë§Œìœ¼ë¡œ ì˜ˆì¸¡í•˜ê¸°
# ========================================
import pandas as pd
import numpy as np
import json
import joblib

# 1. ì„¤ì • ë¡œë“œ
with open('model_config_top5.json', 'r', encoding='utf-8') as f:
    config = json.load(f)

top5_features = config['top5_features']
default_values = config['default_values']

print("í•µì‹¬ 5ê°œ ì»¬ëŸ¼:")
for i, feat in enumerate(top5_features, 1):
    print(f"  {{i}}. {{feat}}")

# 2. ëª¨ë¸ ë¡œë“œ (ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ ì§€ì •)
model1 = joblib.load('saved_models/model1_binary_catboost_YYYYMMDD_HHMMSS.pkl')
scaler1 = joblib.load('saved_models/scaler1_YYYYMMDD_HHMMSS.pkl')
model2 = joblib.load('saved_models/model2_candidate_voting_YYYYMMDD_HHMMSS.pkl')
scaler2 = joblib.load('saved_models/scaler2_YYYYMMDD_HHMMSS.pkl')

# 3. ì…ë ¥ ë°ì´í„° (í•µì‹¬ 5ê°œ ì»¬ëŸ¼ë§Œ ì œê³µ)
input_data_top5 = {{
{chr(10).join(f"    '{feat}': 0.0,  # ì‹¤ì œ ê°’ ì…ë ¥" for feat in top5_features)}
}}

# 4. ì „ì²´ 29ê°œ í”¼ì²˜ë¡œ í™•ì¥
def expand_to_full_features(top5_data, default_values):
    full_data = default_values.copy()
    full_data.update(top5_data)
    return full_data

full_input = expand_to_full_features(input_data_top5, default_values)

# 5. DataFrameìœ¼ë¡œ ë³€í™˜
all_features = top5_features + list(default_values.keys())
X_input = pd.DataFrame([full_input])[all_features]

# 6. ì˜ˆì¸¡
X_scaled = scaler1.transform(X_input)
pred_proba = model1.predict_proba(X_scaled)[0]
confidence = max(pred_proba)

if confidence >= 0.96:
    prediction = "CONFIRMED" if pred_proba[1] > 0.5 else "FALSE POSITIVE"
else:
    X_scaled2 = scaler2.transform(X_input)
    is_candidate = model2.predict(X_scaled2)[0]
    if is_candidate:
        prediction = "CANDIDATE"
    else:
        prediction = "CONFIRMED" if pred_proba[1] > 0.5 else "FALSE POSITIVE"

print(f"\\nì˜ˆì¸¡ ê²°ê³¼: {{prediction}}")
print(f"í™•ì‹ ë„: {{confidence:.4f}}")
"""

with open('predict_with_top5.py', 'w', encoding='utf-8') as f:
    f.write(example_code)
print("âœ… ì‚¬ìš© ì˜ˆì œ: predict_with_top5.py")

print("\n" + "=" * 100)
print("âœ… ë¶„ì„ ì™„ë£Œ!")
print("=" * 100)
print(f"\ní•µì‹¬ 5ê°œ ì»¬ëŸ¼: {', '.join(top5_features)}")
print(f"ë‚˜ë¨¸ì§€ 24ê°œ ì»¬ëŸ¼: ê¸°ë³¸ê°’ ì„¤ì •ë¨")
