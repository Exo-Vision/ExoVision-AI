"""
ì €ì¥ëœ 2-ëª¨ë¸ ì‹œìŠ¤í…œ ë¡œë“œ ë° ì˜ˆì¸¡
- ì…ë ¥: 29ê°œ í”¼ì²˜ (19ê°œ ê¸°ë³¸ + 10ê°œ ì—”ì§€ë‹ˆì–´ë§)
- ì¶œë ¥: 3-í´ë˜ìŠ¤ (CONFIRMED/FALSE POSITIVE/CANDIDATE)
- ê¸°ì¡´ ëª¨ë¸ê³¼ ì™„ì „ í˜¸í™˜
"""

import pandas as pd
import numpy as np
import joblib
import os
import glob
from datetime import datetime

print("=" * 100)
print("ğŸ” ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
print("=" * 100)

# ============================================================================
# ìµœì‹  ëª¨ë¸ ìë™ ë¡œë“œ
# ============================================================================
print("\n[1] ì €ì¥ëœ ëª¨ë¸ ê²€ìƒ‰")
print("-" * 100)

save_dir = '../../saved_models'

# ìµœì‹  config íŒŒì¼ ì°¾ê¸°
config_files = glob.glob(os.path.join(save_dir, 'config_*.pkl'))
if not config_files:
    print("âŒ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
    exit(1)

latest_config_path = max(config_files, key=os.path.getctime)
print(f"ìµœì‹  config: {os.path.basename(latest_config_path)}")

# Config ë¡œë“œ
config = joblib.load(latest_config_path)
timestamp = config['timestamp']

print(f"\nëª¨ë¸ ì •ë³´:")
print(f"  íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}")
print(f"  ëª¨ë¸ 1: {config['model1_name']} ({config['model1_accuracy']*100:.2f}%)")
print(f"  ëª¨ë¸ 2: {config['model2_name']} ({config['model2_accuracy']*100:.2f}%)")
print(f"  ìµœì¢… ì •í™•ë„: {config['final_accuracy']*100:.2f}%")
print(f"  ì„ê³„ê°’: {config['best_threshold']}")
print(f"  í”¼ì²˜ ìˆ˜: {config['feature_count']}ê°œ")

# ============================================================================
# ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
# ============================================================================
print("\n[2] ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ")
print("-" * 100)

model1_path = os.path.join(save_dir, f'model1_ultra_{timestamp}.pkl')
scaler1_path = os.path.join(save_dir, f'scaler1_{timestamp}.pkl')
model2_path = os.path.join(save_dir, f'model2_ultra_{timestamp}.pkl')
scaler2_path = os.path.join(save_dir, f'scaler2_{timestamp}.pkl')

try:
    model1 = joblib.load(model1_path)
    scaler1 = joblib.load(scaler1_path)
    model2 = joblib.load(model2_path)
    scaler2 = joblib.load(scaler2_path)
    print("âœ… ëª¨ë“  ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit(1)

# ============================================================================
# í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í•¨ìˆ˜ (ì…ë ¥ í˜•ì‹ ìœ ì§€)
# ============================================================================
def engineer_features(X_raw):
    """
    ì›ë³¸ 19ê°œ í”¼ì²˜ â†’ 44ê°œ í”¼ì²˜ë¡œ í™•ì¥
    ê¸°ì¡´ ëª¨ë¸ ì…ë ¥ í˜•ì‹ ì™„ì „ í˜¸í™˜
    """
    X = X_raw.copy()
    
    # ê¸°ë³¸ 10ê°œ í”¼ì²˜
    X['planet_star_ratio'] = X['koi_prad'] / (X['koi_srad'] + 1e-10)
    X['orbital_energy'] = 1.0 / (X['koi_sma'] + 1e-10)
    X['transit_signal'] = X['koi_depth'] * X['koi_duration']
    X['stellar_density'] = X['koi_smass'] / (X['koi_srad']**3 + 1e-10)
    X['planet_density_proxy'] = X['koi_prad']**3 / (X['koi_sma']**2 + 1e-10)
    X['log_period'] = np.log1p(X['koi_period'])
    X['log_depth'] = np.log1p(X['koi_depth'])
    X['log_insol'] = np.log1p(X['koi_insol'])
    X['orbit_stability'] = X['koi_eccen'] * X['koi_impact']
    X['transit_snr'] = X['koi_depth'] / (X['koi_duration'] + 1e-10)
    
    # ê³ ê¸‰ 15ê°œ í”¼ì²˜
    X['habitable_zone_score'] = 1.0 / (1.0 + np.abs(X['koi_insol'] - 1.0))
    X['temp_habitable_score'] = 1.0 / (1.0 + np.abs(X['koi_teq'] - 288) / 100)
    X['roche_limit'] = 2.46 * X['koi_srad'] * (X['koi_smass'] / (X['koi_prad'] / 109.0))**(1/3)
    X['hill_sphere'] = X['koi_sma'] * (X['koi_smass'] / 3.0)**(1/3)
    X['transit_probability'] = X['koi_srad'] / (X['koi_sma'] * 215.032 + 1e-10)
    X['improved_snr'] = (X['koi_depth'] * np.sqrt(X['koi_duration'])) / (X['koi_period'] + 1e-10)
    X['stability_index'] = (1 - X['koi_eccen']) * (1 - X['koi_impact'])
    X['mass_ratio'] = (X['koi_prad'] / 109.0)**3 / (X['koi_smass'] + 1e-10)
    X['tidal_heating'] = X['koi_eccen'] / (X['koi_sma']**3 + 1e-10)
    X['duration_ratio'] = X['koi_duration'] / (X['koi_period'] + 1e-10)
    X['radiation_balance'] = X['koi_insol'] * (X['koi_prad']**2) / (X['koi_sma']**2 + 1e-10)
    X['age_metallicity'] = X['koi_sage'] * (X['koi_smet'] + 2.5)
    X['depth_size_ratio'] = X['koi_depth'] / (X['koi_prad']**2 + 1e-10)
    X['kepler_ratio'] = X['koi_period']**2 / (X['koi_sma']**3 + 1e-10)
    X['depth_variability'] = X['koi_depth'] / (X['koi_duration'] * X['koi_period'] + 1e-10)
    
    # Inf, NaN ì²˜ë¦¬
    X = X.replace([np.inf, -np.inf], np.nan)
    X = X.fillna(X.median())
    
    return X

# ============================================================================
# ì˜ˆì¸¡ í•¨ìˆ˜ (2-ëª¨ë¸ íŒŒì´í”„ë¼ì¸)
# ============================================================================
def predict(X_raw):
    """
    2-ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì˜ˆì¸¡
    ì…ë ¥: ì›ë³¸ 19ê°œ í”¼ì²˜
    ì¶œë ¥: 3-í´ë˜ìŠ¤ (CONFIRMED/FALSE POSITIVE/CANDIDATE)
    """
    # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    X_engineered = engineer_features(X_raw)
    
    # ìŠ¤ì¼€ì¼ë§
    X_scaled_1 = scaler1.transform(X_engineered)
    X_scaled_2 = scaler2.transform(X_engineered)
    
    # ëª¨ë¸ 1 ì˜ˆì¸¡ (CONFIRMED vs FALSE POSITIVE)
    stage1_proba = model1.predict_proba(X_scaled_1)
    stage1_pred = model1.predict(X_scaled_1)
    
    # ëª¨ë¸ 2 ì˜ˆì¸¡ (CANDIDATE íŒë³„)
    stage2_pred = model2.predict(X_scaled_2)
    
    # í™•ì‹ ë„ ê¸°ë°˜ ìµœì¢… ì˜ˆì¸¡
    threshold = config['best_threshold']
    final_predictions = np.empty(len(X_raw), dtype=object)
    
    high_conf_mask = (stage1_proba.max(axis=1) >= threshold)
    final_predictions[high_conf_mask] = np.where(
        stage1_pred[high_conf_mask] == 1,
        'CONFIRMED',
        'FALSE POSITIVE'
    )
    
    low_conf_mask = ~high_conf_mask
    final_predictions[low_conf_mask] = np.where(
        stage2_pred[low_conf_mask] == 1,
        'CANDIDATE',
        np.where(stage1_pred[low_conf_mask] == 1, 'CONFIRMED', 'FALSE POSITIVE')
    )
    
    return final_predictions, stage1_proba.max(axis=1)

# ============================================================================
# í…ŒìŠ¤íŠ¸: ë°ì´í„° ë¡œë“œ ë° ì˜ˆì¸¡
# ============================================================================
print("\n[3] í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ì˜ˆì¸¡")
print("-" * 100)

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv('../../dataset/preprocessed_all.csv', low_memory=False)
print(f"ë°ì´í„° ë¡œë“œ: {df.shape[0]:,} ìƒ˜í”Œ")

# íƒ€ê²Ÿ ë¶„ë¦¬
y_true = df['koi_disposition']
X_raw = df.drop(['koi_disposition', 'kepoi_name'], axis=1, errors='ignore')

# ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ (ì›ë³¸ 19ê°œ)
numeric_cols = X_raw.select_dtypes(include=[np.number]).columns
X_raw = X_raw[numeric_cols]

print(f"ì…ë ¥ í”¼ì²˜: {X_raw.shape[1]}ê°œ (ì›ë³¸)")

# ì˜ˆì¸¡ ì‹¤í–‰
print("\nì˜ˆì¸¡ ì¤‘...")
y_pred, confidence = predict(X_raw)

# ============================================================================
# ê²°ê³¼ í‰ê°€
# ============================================================================
print("\n[4] ì˜ˆì¸¡ ê²°ê³¼")
print("-" * 100)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# ì „ì²´ ì •í™•ë„
accuracy = accuracy_score(y_true, y_pred)
print(f"\nâœ… ì „ì²´ ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)")

# ì˜ˆì¸¡ ë¶„í¬
print("\nì˜ˆì¸¡ ë¶„í¬:")
for label in ['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE']:
    count = (y_pred == label).sum()
    print(f"  {label}: {count:,} ({count/len(y_pred)*100:.1f}%)")

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred,
                      labels=['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE'])

print("\nConfusion Matrix:")
print("-" * 100)
print(f"{'':15} {'CANDIDATE':>12} {'CONFIRMED':>12} {'FALSE POS':>12}")
print("-" * 100)
for i, label in enumerate(['CANDIDATE', 'CONFIRMED', 'FALSE POS']):
    print(f"{label:15} {cm[i][0]:>12} {cm[i][1]:>12} {cm[i][2]:>12}")

# Classification Report
print("\nClassification Report:")
print("-" * 100)
print(classification_report(y_true, y_pred,
                           labels=['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE'],
                           target_names=['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE']))

# í´ë˜ìŠ¤ë³„ ì •í™•ë„
print("\ní´ë˜ìŠ¤ë³„ ì •í™•ë„:")
print("-" * 100)
for label in ['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE']:
    mask = y_true == label
    if mask.sum() > 0:
        class_acc = accuracy_score(y_true[mask], y_pred[mask])
        print(f"  {label:20} {class_acc:.4f} ({class_acc*100:.2f}%)  [{mask.sum():,}ê°œ ìƒ˜í”Œ]")

# í™•ì‹ ë„ ë¶„ì„
print("\ní™•ì‹ ë„ ë¶„ì„:")
print("-" * 100)
print(f"  í‰ê·  í™•ì‹ ë„: {confidence.mean():.4f}")
print(f"  ì¤‘ì•™ê°’: {np.median(confidence):.4f}")
print(f"  ìµœì†Œê°’: {confidence.min():.4f}")
print(f"  ìµœëŒ€ê°’: {confidence.max():.4f}")
print(f"  ê³ í™•ì‹ (â‰¥{config['best_threshold']}): {(confidence >= config['best_threshold']).sum():,}ê°œ ({(confidence >= config['best_threshold']).sum()/len(confidence)*100:.1f}%)")

# ============================================================================
# ìƒ˜í”Œ ì˜ˆì¸¡ (ì²˜ìŒ 10ê°œ)
# ============================================================================
print("\n[5] ìƒ˜í”Œ ì˜ˆì¸¡ (ì²˜ìŒ 10ê°œ)")
print("-" * 100)
print(f"{'ì‹¤ì œ':<15} {'ì˜ˆì¸¡':<15} {'í™•ì‹ ë„':<10} {'ì¼ì¹˜':<10}")
print("-" * 100)

for i in range(min(10, len(y_true))):
    match = "âœ…" if y_true.iloc[i] == y_pred[i] else "âŒ"
    print(f"{y_true.iloc[i]:<15} {y_pred[i]:<15} {confidence[i]:.4f}    {match}")

# ============================================================================
# ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡ ì˜ˆì‹œ
# ============================================================================
print("\n[6] ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡ í•¨ìˆ˜")
print("-" * 100)

def predict_new_samples(csv_path):
    """
    ìƒˆë¡œìš´ CSV íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ ì˜ˆì¸¡
    CSVëŠ” 19ê°œ ì›ë³¸ í”¼ì²˜ë§Œ í¬í•¨í•˜ë©´ ë¨
    """
    # ë°ì´í„° ë¡œë“œ
    df_new = pd.read_csv(csv_path, low_memory=False)
    
    # íƒ€ê²Ÿ ì œê±° (ìˆë‹¤ë©´)
    if 'koi_disposition' in df_new.columns:
        df_new = df_new.drop('koi_disposition', axis=1)
    if 'kepoi_name' in df_new.columns:
        names = df_new['kepoi_name']
        df_new = df_new.drop('kepoi_name', axis=1)
    else:
        names = None
    
    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ
    numeric_cols = df_new.select_dtypes(include=[np.number]).columns
    X_new = df_new[numeric_cols]
    
    # ì˜ˆì¸¡
    predictions, confidences = predict(X_new)
    
    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
    result_df = pd.DataFrame({
        'kepoi_name': names if names is not None else range(len(predictions)),
        'prediction': predictions,
        'confidence': confidences
    })
    
    return result_df

print("ì‚¬ìš© ì˜ˆì‹œ:")
print("  result = predict_new_samples('new_data.csv')")
print("  result.to_csv('predictions.csv', index=False)")

print("\n" + "=" * 100)
print("âœ… ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
print("=" * 100)
print(f"\nì…ë ¥ í˜•ì‹: 19ê°œ ì›ë³¸ í”¼ì²˜")
print(f"ì¶œë ¥ í˜•ì‹: 3-í´ë˜ìŠ¤ (CONFIRMED/FALSE POSITIVE/CANDIDATE)")
print(f"ì •í™•ë„: {accuracy*100:.2f}%")
print(f"ì„ê³„ê°’: {config['best_threshold']}")
print("\n" + "=" * 100)
