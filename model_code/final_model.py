"""
ìµœì¢… 2-ëª¨ë¸ ì‹œìŠ¤í…œ
- ëª¨ë¸ 1: CONFIRMED vs FALSE POSITIVE (2-í´ë˜ìŠ¤)
- ëª¨ë¸ 2: CANDIDATE vs NOT_CANDIDATE (CANDIDATE íŒë³„)
- íŒŒì´í”„ë¼ì¸: í™•ì‹ ë„ ê¸°ë°˜ ê³„ì¸µì  ë¶„ë¥˜
- ëª¨ë¸ ì €ì¥/ë¡œë“œ ê¸°ëŠ¥ í¬í•¨
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier

import joblib
import os
from datetime import datetime

print("=" * 100)
print("ğŸ¯ ìµœì¢… 2-ëª¨ë¸ ì‹œìŠ¤í…œ: CONFIRMED/FALSE POSITIVE + CANDIDATE íŒë³„")
print("=" * 100)

# ============================================================================
# ë°ì´í„° ë¡œë“œ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
# ============================================================================
print("\n[ë°ì´í„° ë¡œë“œ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§]")
print("-" * 100)

df = pd.read_csv('datasets/exoplanets.csv', low_memory=False)
print(f"ì›ë³¸ ë°ì´í„°: {df.shape[0]:,} ìƒ˜í”Œ")

# íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸
print(f"íƒ€ê²Ÿ ë¶„í¬:")
for label, count in df['koi_disposition'].value_counts().items():
    print(f"  {label}: {count:,}")

y_full = df['koi_disposition']
X_full = df.drop(['koi_disposition', 'kepoi_name'], axis=1, errors='ignore')

# ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ
numeric_cols = X_full.select_dtypes(include=[np.number]).columns
X_full = X_full[numeric_cols]
print(f"ê¸°ë³¸ í”¼ì²˜: {len(numeric_cols)}ê°œ")

# í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (29ê°œ í”¼ì²˜)
print("\ní”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì¤‘...")
X_full['planet_star_ratio'] = X_full['koi_prad'] / (X_full['koi_srad'] + 1e-10)
X_full['orbital_energy'] = 1.0 / (X_full['koi_sma'] + 1e-10)
X_full['transit_signal'] = X_full['koi_depth'] * X_full['koi_duration']
X_full['stellar_density'] = X_full['koi_smass'] / (X_full['koi_srad']**3 + 1e-10)
X_full['planet_density_proxy'] = X_full['koi_prad']**3 / (X_full['koi_sma']**2 + 1e-10)
X_full['log_period'] = np.log1p(X_full['koi_period'])
X_full['log_depth'] = np.log1p(X_full['koi_depth'])
X_full['log_insol'] = np.log1p(X_full['koi_insol'])
X_full['orbit_stability'] = X_full['koi_eccen'] * X_full['koi_impact']
X_full['transit_snr'] = X_full['koi_depth'] / (X_full['koi_duration'] + 1e-10)

X_full = X_full.replace([np.inf, -np.inf], np.nan)
X_full = X_full.fillna(X_full.median())

print(f"ìµœì¢… í”¼ì²˜ ìˆ˜: {X_full.shape[1]}ê°œ")

# ============================================================================
# ëª¨ë¸ 1: CONFIRMED vs FALSE POSITIVE (2-í´ë˜ìŠ¤)
# ============================================================================
print("\n" + "=" * 100)
print("ğŸ”µ ëª¨ë¸ 1: CONFIRMED vs FALSE POSITIVE")
print("=" * 100)

y_binary = y_full[y_full.isin(['CONFIRMED', 'FALSE POSITIVE'])]
X_binary = X_full.loc[y_binary.index]

print(f"\ní•™ìŠµ ë°ì´í„°:")
print(f"  ì´ ìƒ˜í”Œ: {len(y_binary):,}")
for label, count in y_binary.value_counts().sort_index().items():
    print(f"  {label}: {count:,} ({count/len(y_binary)*100:.1f}%)")

y_binary_encoded = (y_binary == 'CONFIRMED').astype(int)

X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(
    X_binary, y_binary_encoded, test_size=0.1, random_state=42, stratify=y_binary_encoded
)

print(f"\nTrain: {len(y_train_1):,} / Test: {len(y_test_1):,}")

# ìŠ¤ì¼€ì¼ë§
scaler_1 = StandardScaler()
X_train_1_scaled = scaler_1.fit_transform(X_train_1)
X_test_1_scaled = scaler_1.transform(X_test_1)

# ì—¬ëŸ¬ ëª¨ë¸ í…ŒìŠ¤íŠ¸
print("\nëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...")

models_1 = {
    'CatBoost': CatBoostClassifier(
        iterations=500, depth=4, learning_rate=0.02,
        l2_leaf_reg=10.0, bagging_temperature=1.0,
        random_state=42, verbose=False
    ),
    'XGBoost': XGBClassifier(
        n_estimators=500, max_depth=4, learning_rate=0.02,
        subsample=0.7, colsample_bytree=0.7,
        reg_alpha=2.0, reg_lambda=10.0,
        random_state=42, eval_metric='logloss'
    ),
    'LightGBM': LGBMClassifier(
        n_estimators=500, max_depth=4, learning_rate=0.02,
        subsample=0.7, colsample_bytree=0.7,
        reg_alpha=2.0, reg_lambda=10.0,
        random_state=42, verbose=-1
    )
}

results_1 = {}

for name, model in models_1.items():
    print(f"\n{name} í•™ìŠµ ì¤‘...")
    model.fit(X_train_1_scaled, y_train_1)
    
    train_acc = accuracy_score(y_train_1, model.predict(X_train_1_scaled))
    test_acc = accuracy_score(y_test_1, model.predict(X_test_1_scaled))
    cv_scores = cross_val_score(model, X_train_1_scaled, y_train_1, cv=5, scoring='accuracy')
    
    results_1[name] = {
        'model': model,
        'train_acc': train_acc,
        'test_acc': test_acc,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'overfitting': train_acc - test_acc
    }
    
    print(f"  Train: {train_acc:.4f} | Test: {test_acc:.4f} | CV: {cv_scores.mean():.4f}Â±{cv_scores.std():.4f}")
    print(f"  ê³¼ì í•©: {(train_acc - test_acc)*100:.2f}%p")

# Voting Ensemble
print("\nVoting Ensemble í•™ìŠµ ì¤‘...")
voting_1 = VotingClassifier(
    estimators=[(name, model) for name, model in models_1.items()],
    voting='soft'
)
voting_1.fit(X_train_1_scaled, y_train_1)

train_acc_v1 = accuracy_score(y_train_1, voting_1.predict(X_train_1_scaled))
test_acc_v1 = accuracy_score(y_test_1, voting_1.predict(X_test_1_scaled))
cv_scores_v1 = cross_val_score(voting_1, X_train_1_scaled, y_train_1, cv=5, scoring='accuracy')

results_1['Voting'] = {
    'model': voting_1,
    'train_acc': train_acc_v1,
    'test_acc': test_acc_v1,
    'cv_mean': cv_scores_v1.mean(),
    'cv_std': cv_scores_v1.std(),
    'overfitting': train_acc_v1 - test_acc_v1
}

print(f"  Train: {train_acc_v1:.4f} | Test: {test_acc_v1:.4f} | CV: {cv_scores_v1.mean():.4f}Â±{cv_scores_v1.std():.4f}")
print(f"  ê³¼ì í•©: {(train_acc_v1 - test_acc_v1)*100:.2f}%p")

# ìµœê³  ëª¨ë¸ ì„ íƒ
best_1 = max(results_1.items(), key=lambda x: x[1]['test_acc'])
print(f"\nâœ… ëª¨ë¸ 1 ìµœê³ : {best_1[0]} - {best_1[1]['test_acc']:.4f} ({best_1[1]['test_acc']*100:.2f}%)")

# ============================================================================
# ëª¨ë¸ 2: CANDIDATE vs NOT_CANDIDATE
# ============================================================================
print("\n" + "=" * 100)
print("ğŸŸ¢ ëª¨ë¸ 2: CANDIDATE íŒë³„ (IS_CANDIDATE vs NOT_CANDIDATE)")
print("=" * 100)

y_candidate = (y_full == 'CANDIDATE').astype(int)
X_candidate = X_full.copy()

print(f"\ní•™ìŠµ ë°ì´í„°:")
print(f"  ì´ ìƒ˜í”Œ: {len(y_candidate):,}")
print(f"  CANDIDATE: {y_candidate.sum():,} ({y_candidate.sum()/len(y_candidate)*100:.1f}%)")
print(f"  NOT CANDIDATE: {(~y_candidate.astype(bool)).sum():,} ({(~y_candidate.astype(bool)).sum()/len(y_candidate)*100:.1f}%)")

X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(
    X_candidate, y_candidate, test_size=0.1, random_state=42, stratify=y_candidate
)

print(f"\nTrain: {len(y_train_2):,} / Test: {len(y_test_2):,}")

# ìŠ¤ì¼€ì¼ë§
scaler_2 = StandardScaler()
X_train_2_scaled = scaler_2.fit_transform(X_train_2)
X_test_2_scaled = scaler_2.transform(X_test_2)

# ì—¬ëŸ¬ ëª¨ë¸ í…ŒìŠ¤íŠ¸
print("\nëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...")

models_2 = {
    'CatBoost': CatBoostClassifier(
        iterations=500, depth=4, learning_rate=0.02,
        l2_leaf_reg=10.0, bagging_temperature=1.0,
        random_state=42, verbose=False
    ),
    'XGBoost': XGBClassifier(
        n_estimators=500, max_depth=4, learning_rate=0.02,
        subsample=0.7, colsample_bytree=0.7,
        reg_alpha=2.0, reg_lambda=10.0,
        random_state=42, eval_metric='logloss'
    ),
    'LightGBM': LGBMClassifier(
        n_estimators=500, max_depth=4, learning_rate=0.02,
        subsample=0.7, colsample_bytree=0.7,
        reg_alpha=2.0, reg_lambda=10.0,
        random_state=42, verbose=-1
    ),
    'Neural Network': MLPClassifier(
        hidden_layer_sizes=(128, 64, 32),
        activation='relu',
        alpha=0.01,
        max_iter=500,
        early_stopping=True,
        random_state=42
    )
}

results_2 = {}

for name, model in models_2.items():
    print(f"\n{name} í•™ìŠµ ì¤‘...")
    model.fit(X_train_2_scaled, y_train_2)
    
    train_acc = accuracy_score(y_train_2, model.predict(X_train_2_scaled))
    test_acc = accuracy_score(y_test_2, model.predict(X_test_2_scaled))
    cv_scores = cross_val_score(model, X_train_2_scaled, y_train_2, cv=5, scoring='accuracy')
    
    results_2[name] = {
        'model': model,
        'train_acc': train_acc,
        'test_acc': test_acc,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'overfitting': train_acc - test_acc
    }
    
    print(f"  Train: {train_acc:.4f} | Test: {test_acc:.4f} | CV: {cv_scores.mean():.4f}Â±{cv_scores.std():.4f}")
    print(f"  ê³¼ì í•©: {(train_acc - test_acc)*100:.2f}%p")

# Voting Ensemble
print("\nVoting Ensemble í•™ìŠµ ì¤‘...")
voting_2 = VotingClassifier(
    estimators=[(name, model) for name, model in models_2.items()],
    voting='soft'
)
voting_2.fit(X_train_2_scaled, y_train_2)

train_acc_v2 = accuracy_score(y_train_2, voting_2.predict(X_train_2_scaled))
test_acc_v2 = accuracy_score(y_test_2, voting_2.predict(X_test_2_scaled))
cv_scores_v2 = cross_val_score(voting_2, X_train_2_scaled, y_train_2, cv=5, scoring='accuracy')

results_2['Voting'] = {
    'model': voting_2,
    'train_acc': train_acc_v2,
    'test_acc': test_acc_v2,
    'cv_mean': cv_scores_v2.mean(),
    'cv_std': cv_scores_v2.std(),
    'overfitting': train_acc_v2 - test_acc_v2
}

print(f"  Train: {train_acc_v2:.4f} | Test: {test_acc_v2:.4f} | CV: {cv_scores_v2.mean():.4f}Â±{cv_scores_v2.std():.4f}")
print(f"  ê³¼ì í•©: {(train_acc_v2 - test_acc_v2)*100:.2f}%p")

# ìµœê³  ëª¨ë¸ ì„ íƒ
best_2 = max(results_2.items(), key=lambda x: x[1]['test_acc'])
print(f"\nâœ… ëª¨ë¸ 2 ìµœê³ : {best_2[0]} - {best_2[1]['test_acc']:.4f} ({best_2[1]['test_acc']*100:.2f}%)")

# ============================================================================
# íŒŒì´í”„ë¼ì¸ í†µí•©: í™•ì‹ ë„ ê¸°ë°˜ ë¶„ë¥˜
# ============================================================================
print("\n" + "=" * 100)
print("ğŸ”— íŒŒì´í”„ë¼ì¸ í†µí•©: í™•ì‹ ë„ ê¸°ë°˜ 3-í´ë˜ìŠ¤ ë¶„ë¥˜")
print("=" * 100)

# ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
y_test_full = y_full.loc[X_test_2.index]
X_test_full_scaled_1 = scaler_1.transform(X_test_2)
X_test_full_scaled_2 = scaler_2.transform(X_test_2)

# ëª¨ë¸ 1 ì˜ˆì¸¡
model1 = best_1[1]['model']
stage1_proba = model1.predict_proba(X_test_full_scaled_1)
stage1_pred = model1.predict(X_test_full_scaled_1)

# ëª¨ë¸ 2 ì˜ˆì¸¡
model2 = best_2[1]['model']
stage2_proba = model2.predict_proba(X_test_full_scaled_2)
stage2_pred = model2.predict(X_test_full_scaled_2)

# í™•ì‹ ë„ ì„ê³„ê°’ ìµœì í™”
thresholds = [0.80, 0.85, 0.90, 0.92, 0.94, 0.96]

print(f"\n{'ì„ê³„ê°’':<10} {'1ë‹¨ê³„ì‚¬ìš©':<12} {'CANDIDATEìˆ˜':<12} {'ìµœì¢…ì •í™•ë„':<12}")
print("-" * 100)

best_threshold = 0.90
best_accuracy = 0.0
best_predictions = None

for threshold in thresholds:
    final_predictions = np.empty(len(y_test_full), dtype=object)
    
    # 1ë‹¨ê³„ í™•ì‹ ë„ê°€ ë†’ì€ ì¼€ì´ìŠ¤ â†’ CONFIRMED or FALSE POSITIVE
    high_conf_mask = (stage1_proba.max(axis=1) >= threshold)
    final_predictions[high_conf_mask] = np.where(
        stage1_pred[high_conf_mask] == 1,
        'CONFIRMED',
        'FALSE POSITIVE'
    )
    
    # 1ë‹¨ê³„ í™•ì‹ ë„ê°€ ë‚®ì€ ì¼€ì´ìŠ¤ â†’ CANDIDATE íŒë³„
    low_conf_mask = ~high_conf_mask
    final_predictions[low_conf_mask] = np.where(
        stage2_pred[low_conf_mask] == 1,
        'CANDIDATE',
        np.where(stage1_pred[low_conf_mask] == 1, 'CONFIRMED', 'FALSE POSITIVE')
    )
    
    accuracy = accuracy_score(y_test_full, final_predictions)
    stage1_ratio = high_conf_mask.sum() / len(y_test_full) * 100
    candidate_count = (final_predictions == 'CANDIDATE').sum()
    
    print(f"{threshold:.2f}      {stage1_ratio:>6.1f}%      {candidate_count:>4}ê°œ       {accuracy:.4f}")
    
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_threshold = threshold
        best_predictions = final_predictions.copy()

print(f"\nâœ… ìµœì  ì„ê³„ê°’: {best_threshold:.2f}")
print(f"âœ… ìµœì¢… ì •í™•ë„: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)")

# ============================================================================
# ìµœì¢… í‰ê°€
# ============================================================================
print("\n" + "=" * 100)
print("ğŸ“Š ìµœì¢… ì„±ëŠ¥ í‰ê°€")
print("=" * 100)

print("\nëª¨ë¸ë³„ ì •í™•ë„:")
print("-" * 100)
print(f"ëª¨ë¸ 1 (CONFIRMED vs FALSE POSITIVE): {best_1[1]['test_acc']:.4f} ({best_1[1]['test_acc']*100:.2f}%)")
print(f"ëª¨ë¸ 2 (CANDIDATE íŒë³„):              {best_2[1]['test_acc']:.4f} ({best_2[1]['test_acc']*100:.2f}%)")
print(f"ìµœì¢… í†µí•© (3-í´ë˜ìŠ¤):                 {best_accuracy:.4f} ({best_accuracy*100:.2f}%)")

# Confusion Matrix
cm = confusion_matrix(y_test_full, best_predictions,
                      labels=['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE'])

print("\nConfusion Matrix:")
print("-" * 100)
print(f"{'':15} {'CANDIDATE':>12} {'CONFIRMED':>12} {'FALSE POS':>12}")
print("-" * 100)
for i, label in enumerate(['CANDIDATE', 'CONFIRMED', 'FALSE POS']):
    print(f"{label:15} {cm[i][0]:>12} {cm[i][1]:>12} {cm[i][2]:>12}")

# Classification Report
print("\nClassification Report:")
print("-" * 100)
print(classification_report(y_test_full, best_predictions,
                           labels=['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE'],
                           target_names=['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE']))

# í´ë˜ìŠ¤ë³„ ì •í™•ë„
print("\ní´ë˜ìŠ¤ë³„ ì •í™•ë„:")
print("-" * 100)
for label in ['CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE']:
    mask = y_test_full == label
    if mask.sum() > 0:
        class_acc = accuracy_score(y_test_full[mask], best_predictions[mask])
        print(f"  {label:20} {class_acc:.4f} ({class_acc*100:.2f}%)  [{mask.sum()}ê°œ ìƒ˜í”Œ]")

# ============================================================================
# ëª¨ë¸ ì €ì¥
# ============================================================================
print("\n" + "=" * 100)
print("ğŸ’¾ ëª¨ë¸ ì €ì¥")
print("=" * 100)

# ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
save_dir = 'saved_models'
os.makedirs(save_dir, exist_ok=True)

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# ëª¨ë¸ 1 ì €ì¥
model1_path = os.path.join(save_dir, f'model1_binary_{best_1[0].lower().replace(" ", "_")}_{timestamp}.pkl')
scaler1_path = os.path.join(save_dir, f'scaler1_{timestamp}.pkl')

joblib.dump(model1, model1_path)
joblib.dump(scaler_1, scaler1_path)
print(f"âœ… ëª¨ë¸ 1 ì €ì¥: {model1_path}")
print(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ 1 ì €ì¥: {scaler1_path}")

# ëª¨ë¸ 2 ì €ì¥
model2_path = os.path.join(save_dir, f'model2_candidate_{best_2[0].lower().replace(" ", "_")}_{timestamp}.pkl')
scaler2_path = os.path.join(save_dir, f'scaler2_{timestamp}.pkl')

joblib.dump(model2, model2_path)
joblib.dump(scaler_2, scaler2_path)
print(f"âœ… ëª¨ë¸ 2 ì €ì¥: {model2_path}")
print(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ 2 ì €ì¥: {scaler2_path}")

# ì„¤ì • ì €ì¥
config = {
    'model1_name': best_1[0],
    'model1_accuracy': best_1[1]['test_acc'],
    'model2_name': best_2[0],
    'model2_accuracy': best_2[1]['test_acc'],
    'best_threshold': best_threshold,
    'final_accuracy': best_accuracy,
    'timestamp': timestamp,
    'feature_count': X_full.shape[1]
}

config_path = os.path.join(save_dir, f'config_{timestamp}.pkl')
joblib.dump(config, config_path)
print(f"âœ… ì„¤ì • ì €ì¥: {config_path}")

print("\n" + "=" * 100)
print("ğŸ“‚ ì €ì¥ëœ íŒŒì¼:")
print("=" * 100)
print(f"  â€¢ {model1_path}")
print(f"  â€¢ {scaler1_path}")
print(f"  â€¢ {model2_path}")
print(f"  â€¢ {scaler2_path}")
print(f"  â€¢ {config_path}")

# ============================================================================
# ëª¨ë¸ ë¡œë“œ ì˜ˆì œ ì½”ë“œ ìƒì„±
# ============================================================================
load_example = f"""
# ============================================================================
# ëª¨ë¸ ë¡œë“œ ë° ì‚¬ìš© ì˜ˆì œ
# ============================================================================

import joblib
import numpy as np
import pandas as pd

# ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
model1 = joblib.load('{model1_path}')
scaler1 = joblib.load('{scaler1_path}')
model2 = joblib.load('{model2_path}')
scaler2 = joblib.load('{scaler2_path}')
config = joblib.load('{config_path}')

print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
print(f"ëª¨ë¸ 1: {{config['model1_name']}} - {{config['model1_accuracy']*100:.2f}}%")
print(f"ëª¨ë¸ 2: {{config['model2_name']}} - {{config['model2_accuracy']*100:.2f}}%")
print(f"ìµœì¢… ì •í™•ë„: {{config['final_accuracy']*100:.2f}}%")
print(f"ìµœì  ì„ê³„ê°’: {{config['best_threshold']:.2f}}")

# ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡
def predict_exoplanet(X_new):
    \"\"\"
    ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ 3-í´ë˜ìŠ¤ ì˜ˆì¸¡
    X_new: pandas DataFrame (í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œëœ ë°ì´í„°)
    \"\"\"
    # ìŠ¤ì¼€ì¼ë§
    X_scaled_1 = scaler1.transform(X_new)
    X_scaled_2 = scaler2.transform(X_new)
    
    # ëª¨ë¸ 1 ì˜ˆì¸¡
    proba1 = model1.predict_proba(X_scaled_1)
    pred1 = model1.predict(X_scaled_1)
    
    # ëª¨ë¸ 2 ì˜ˆì¸¡
    pred2 = model2.predict(X_scaled_2)
    
    # ìµœì¢… ì˜ˆì¸¡
    final_pred = []
    for i in range(len(X_new)):
        if proba1[i].max() >= config['best_threshold']:
            # ê³ í™•ì‹ ë„ â†’ ëª¨ë¸ 1 ê²°ê³¼ ì‚¬ìš©
            final_pred.append('CONFIRMED' if pred1[i] == 1 else 'FALSE POSITIVE')
        else:
            # ì €í™•ì‹ ë„ â†’ ëª¨ë¸ 2ë¡œ CANDIDATE íŒë³„
            if pred2[i] == 1:
                final_pred.append('CANDIDATE')
            else:
                final_pred.append('CONFIRMED' if pred1[i] == 1 else 'FALSE POSITIVE')
    
    return final_pred

# ì‚¬ìš© ì˜ˆì‹œ:
# predictions = predict_exoplanet(X_new_data)
"""

example_path = os.path.join(save_dir, f'load_and_predict_example_{timestamp}.py')
with open(example_path, 'w', encoding='utf-8') as f:
    f.write(load_example)

print(f"\nâœ… ì‚¬ìš© ì˜ˆì œ ì½”ë“œ ì €ì¥: {example_path}")

print("\n" + "=" * 100)
print("âœ… ìµœì¢… 2-ëª¨ë¸ ì‹œìŠ¤í…œ ì™„ë£Œ!")
print("=" * 100)

print(f"\nğŸ¯ ìµœì¢… ê²°ê³¼:")
print(f"  â€¢ ëª¨ë¸ 1 ({best_1[0]}): {best_1[1]['test_acc']*100:.2f}%")
print(f"  â€¢ ëª¨ë¸ 2 ({best_2[0]}): {best_2[1]['test_acc']*100:.2f}%")
print(f"  â€¢ í†µí•© ì‹œìŠ¤í…œ: {best_accuracy*100:.2f}%")

if best_accuracy >= 0.95:
    print("\nğŸ‰ğŸ‰ğŸ‰ 95% ëª©í‘œ ë‹¬ì„±! ğŸ‰ğŸ‰ğŸ‰")
elif best_accuracy >= 0.90:
    print(f"\nğŸ’ª 90% ì´ìƒ ë‹¬ì„±! ëª©í‘œê¹Œì§€ {(0.95-best_accuracy)*100:.2f}%p")
else:
    print(f"\nğŸ“Š ì¶”ê°€ ê°œì„  í•„ìš”: {(0.95-best_accuracy)*100:.2f}%p")

print("\n" + "=" * 100)
